{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Homework 3. Classical approach and embedding\n",
    "\n",
    " ** Author: Talyanskaya Marina **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and comments\n",
    "The initial plan was (and still mostly is):\n",
    "1. To look at the datasets\n",
    "2. To clean data (finally managed to do only separately)\n",
    "3. To apply tfidf as 'classical approch'\n",
    "4. To apply Word2vec as an example of embedding\n",
    "5. To apply Random forest and Logistic regression classifiers to both approaches\n",
    "6. Some tuning\n",
    "7. Final comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: after looking on dataset I decided to work only with train.tsv as test.tsv provides no signs of classes and I would fail to estimate the work of my classifiers. The sampleSabmission file contained only 2nd class signs that seems to be weird, so, I did as seemed to be logical.\n",
    "\n",
    "The choice of Random forest and Logregression as classifiers is based on the fact that they both can work with tfidf and word2vec and take relatively little time and computational resources to use.\n",
    "\n",
    "F1-score metric was chosen due to its ability to take into account not only the number of correct predictions but also a number of missed elements of each class (i.e. includes both precision and recall). As usually, though...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "local_zip = '//jet/prs/workspace/movie-review-sentiment-analysis-kernels-only.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/home/talyanskaya_marina/train_movie_review')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/talyanskaya_marina/train_movie_review/train.tsv', sep=\"\\t\")\n",
    "test = pd.read_csv('/home/talyanskaya_marina/train_movie_review/test.tsv', sep=\"\\t\")\n",
    "sub = pd.read_csv('/home/talyanskaya_marina/train_movie_review/sampleSubmission.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAFvCAYAAABeqyJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAZxIzaNcssAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "train.groupby('Sentiment').Phrase.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, the classes are imbalanced that may cause some problems..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical approach: tfidf + LogRegression and Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verctorizing text using classical tfidf approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = train['Phrase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer(ngram_range=(1,3),max_df=0.95,min_df=10,sublinear_tf=True, stop_words='english')\n",
    "trainv =tfidf.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 30560)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainv, train.Sentiment, test_size=0.3, random_state = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Trying Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_RF_tfidf = RandomForestClassifier()\n",
    "clf_RF_tfidf.fit(X_train, y_train)\n",
    "y_rf = clf_RF_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.37      0.40      2128\n",
      "           1       0.52      0.46      0.49      8215\n",
      "           2       0.71      0.79      0.75     23852\n",
      "           3       0.54      0.48      0.51      9853\n",
      "           4       0.47      0.40      0.43      2770\n",
      "\n",
      "    accuracy                           0.63     46818\n",
      "   macro avg       0.53      0.50      0.52     46818\n",
      "weighted avg       0.61      0.63      0.62     46818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/jet/var/python/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Trying Logistic regression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR_tfidf = LogisticRegression()\n",
    "clf_LR_tfidf.fit(X_train, y_train)\n",
    "y_lr = clf_LR_tfidf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.16      0.25      2128\n",
      "           1       0.53      0.29      0.38      8215\n",
      "           2       0.64      0.90      0.75     23852\n",
      "           3       0.56      0.42      0.48      9853\n",
      "           4       0.57      0.20      0.30      2770\n",
      "\n",
      "    accuracy                           0.62     46818\n",
      "   macro avg       0.58      0.39      0.43     46818\n",
      "weighted avg       0.60      0.62      0.58     46818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try to tune it: Grid search + cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of the parameter grid for Logistic regression\n",
    "param_grid_LR = {'penalty': ['l1', 'l2'],'C': [0.001, 0.01, 1, 100]}\n",
    "\n",
    "# looking for best model\n",
    "tunning_LR = GridSearchCV(clf_LR_tfidf, param_grid_LR, scoring = 'f1_weighted', cv = 5)\n",
    "tunning_LR.fit(X_train, y_train)\n",
    "\n",
    "# checking what is the best model\n",
    "tunning_LR.best_estimator_\n",
    "print(\"Parameters:\" ,tunning_LR.best_params_)\n",
    "print(\"Score:\",tunning_LR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of the parameter grid for Random Forest\n",
    "param_grid_RF = {'n_estimators:': 10, 100, 500,'max_depth': 10, 100}\n",
    "\n",
    "# looking for best model\n",
    "tunning_RF = GridSearchCV(clf_RF_tfidf, param_grid_RF, scoring = 'f1_weighted', cv = 5)\n",
    "tunning_RF.fit(X_train, y_train)\n",
    "\n",
    "# checking what is the best model\n",
    "tunning_RF.best_estimator_\n",
    "print(\"Parameters:\" ,tunning_RF.best_params_)\n",
    "print(\"Score:\",tunning_RF.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, as far as we can see, tuning with Grid Search and cross validation didn't really help our models (and took lots of time...), the best results are still around 0.62-0.63 with F1-score metric (shown by Random forest classifier on tfidf-ed data), that is really poor. An intersting note: it performs relatively ok on 2nd class, it seems to be due to it huge size compared to the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try word2vec..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /jet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /jet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /jet/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data preparation (cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(train):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in tqdm(df['Phrase']):\n",
    "        \n",
    "        #remove html content\n",
    "        review_text = BeautifulSoup(sent).get_text()\n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "        #stop words removal\n",
    "        omit_words = set(stopwords.words('english'))\n",
    "        words = [x for x in words if x not in omit_words]\n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156060 [00:00<?, ?it/s]/jet/var/python/lib/python3.6/site-packages/bs4/__init__.py:272: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "100%|██████████| 156060/156060 [04:47<00:00, 543.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#cleaned reviews for train dataset\n",
    "train_sentences = clean_sentences(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156060\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=train.Sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word2vec applying\n",
    "model_w2v = word2vec.Word2Vec(train_sentences, workers=180, size=num_features, min_count = 35, window = 15, sample = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeatureVector(words, model, num_features):\n",
    "    featureVector = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nWords = 0\n",
    "    index2word_set = set(model_w2v.wv.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nWords = nWords + 1.\n",
    "            featureVector = np.add(featureVector,model[word])\n",
    "    if(nWords != 0):\n",
    "        featureVector = np.divide(featureVector,nWords)\n",
    "    return featureVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageFeatureVectors(sentences, model, num_features):\n",
    "    overallFeatureVectors = []\n",
    "    for sentence in tqdm(sentences):\n",
    "        overallFeatureVectors.append(createFeatureVector(sentence, model, num_features)) \n",
    "    return overallFeatureVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156060 [00:00<?, ?it/s]/jet/var/python/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n",
      "100%|██████████| 156060/156060 [00:36<00:00, 4263.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_vect = averagegFeatureVectors(train_sentences, model_w2v, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into train and test sets.\n",
    "X_train2,X_test2,y_train2,y_test2=train_test_split(train_vect, target, test_size=0.3, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   59.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=-1, oob_score=True, random_state=100, verbose=1,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_w2v = RandomForestClassifier(random_state=100, n_estimators=500, verbose=1, n_jobs=-1, oob_score=True)\n",
    "model_rf_w2v.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.29      0.35      2122\n",
      "           1       0.51      0.37      0.43      8182\n",
      "           2       0.66      0.83      0.74     23874\n",
      "           3       0.53      0.44      0.48      9878\n",
      "           4       0.50      0.31      0.38      2762\n",
      "\n",
      "    accuracy                           0.61     46818\n",
      "   macro avg       0.53      0.45      0.48     46818\n",
      "weighted avg       0.59      0.61      0.59     46818\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_rf_w2v = model_rf_w2v.predict(X_test2)\n",
    "print(metrics.classification_report(y_test2, y_rf_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/jet/var/python/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_lr_w2v = LogisticRegression()\n",
    "model_lr_w2v.fit(X_train2, y_train2)\n",
    "y_lr_w2v = model_lr_w2v.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.01      0.02      2122\n",
      "           1       0.33      0.03      0.06      8182\n",
      "           2       0.53      0.94      0.68     23874\n",
      "           3       0.42      0.15      0.22      9878\n",
      "           4       0.27      0.01      0.02      2762\n",
      "\n",
      "    accuracy                           0.52     46818\n",
      "   macro avg       0.40      0.23      0.20     46818\n",
      "weighted avg       0.45      0.52      0.41     46818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test2, y_lr_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning on Word2vec: Grid search + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of the parameter grid for Logistic regression\n",
    "param_grid_LR2 = {'penalty': ['l1', 'l2'],'C': [0.001, 0.01, 1, 100]}\n",
    "\n",
    "# looking for best model\n",
    "tunning_LR2 = GridSearchCV(model_lr_w2v, param_grid_LR2, scoring = 'f1_weighted', cv = 5)\n",
    "tunning_LR2.fit(X_train2, y_train2)\n",
    "\n",
    "# checking what is the best model\n",
    "tunning_LR2.best_estimator_\n",
    "print(\"Parameters:\" ,tunning_LR2.best_params_)\n",
    "print(\"Score:\",tunning_LR2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of the parameter grid for Random Forest\n",
    "param_grid_RF2 = {'n_estimators:': 10, 100, 500, 'max_depth': 10, 100}\n",
    "\n",
    "# looking for best model\n",
    "tunning_RF2 = GridSearchCV(model_rf_w2v, param_grid_RF, scoring = 'f1_weighted', cv = 5)\n",
    "tunning_RF2.fit(X_train2, y_train2)\n",
    "\n",
    "# checking what is the best model\n",
    "tunning_RF2.best_estimator_\n",
    "print(\"Parameters:\" ,tunning_RF2.best_params_)\n",
    "print(\"Score:\",tunning_RF2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, two hours of grid search didn't improve the situtation, the best results are still around 0.6 on F1-score measure (Random forest classifier with n_estimators=500). And again they are very poor and 2nd performed better than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments\n",
    "\n",
    "I am not sure if I made it correctly (especially with Word2vec appoach), all in all, it perform pretty bad. The best result was shown by Random Forest Classifier on tf-idf ('classical') approach with 0.63 F1-score, however, the difference is really small (Random Forest on Word2vec was close to 0.6) to argue that the classical approach is really better.\n",
    "And it still seems I did something wrong, I can't believe it be just a little bit better than random..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
