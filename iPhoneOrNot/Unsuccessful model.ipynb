{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iPhone case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Sofia Shchipinskaya*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import resnet50, inception_v3, vgg16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from classification_models.resnet import ResNet18\n",
    "from keras.models import load_model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preporation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='full dataset\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not=glob.glob(os.path.join(path,'An/*/','*.jpg'))\n",
    "Iphone=glob.glob(os.path.join(path,'Ip/*/','*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(path,'val'))\n",
    "os.mkdir(os.path.join(path,'train'))\n",
    "os.mkdir(os.path.join(path,'test'))\n",
    "for t in ['train/','val/','test/']:\n",
    "    for folder in ['An','Ip']:\n",
    "        os.mkdir(os.path.join(path,t,folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=np.append(Not,Iphone)\n",
    "shuffle=np.random.permutation(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in shuffle[:2000]:\n",
    "    folder=files[i].split('\\\\')[1]\n",
    "    image=files[i].split('\\\\')[-1]\n",
    "    os.rename(files[i],path+'val\\\\'+folder+'\\\\'+ str(i)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in shuffle[2000:-2000]:\n",
    "    folder=files[i].split('\\\\')[1]\n",
    "    image=files[i].split('\\\\')[-1]\n",
    "    os.rename(files[i],path+'train\\\\'+folder+'\\\\'+ str(i)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in shuffle[-2000:]:\n",
    "    folder=files[i].split('\\\\')[1]\n",
    "    image=files[i].split('\\\\')[-1]\n",
    "    os.rename(files[i],path+'test\\\\'+folder+'\\\\'+ str(i)+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating random transformation\n",
    "val_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 48684 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# creating data loaders\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        'full dataset/val',  \n",
    "        target_size=(224, 224),  \n",
    "        batch_size=16,\n",
    "        class_mode='binary')  \n",
    "\n",
    "train_generator = val_datagen.flow_from_directory(\n",
    "        'full dataset/train',  \n",
    "        target_size=(224, 224),  \n",
    "        batch_size=16,\n",
    "        class_mode='binary')  \n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "        'full dataset/test',  \n",
    "        target_size=(224, 224),  \n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'An': 0, 'Ip': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/classification_models.git\n",
      "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-6qibrunu\n",
      "Requirement already satisfied (use --upgrade to upgrade): image-classifiers==0.2.2 from git+https://github.com/qubvel/classification_models.git in ./anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: keras>=2.1.0 in ./anaconda3/lib/python3.6/site-packages (from image-classifiers==0.2.2) (2.2.4)\n",
      "Requirement already satisfied: h5py in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (2.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (5.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.16.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.2.1)\n",
      "Building wheels for collected packages: image-classifiers\n",
      "  Building wheel for image-classifiers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-l4u4iba6/wheels/de/2b/fd/29a6d33edb8c28bc7d94e95ea1d39c9a218ac500a3cfb1b197\n",
      "Successfully built image-classifiers\n"
     ]
    }
   ],
   "source": [
    "# installing ResNet18\n",
    "!pip install git+https://github.com/qubvel/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shipinskaya_sofi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# building the model\n",
    "base_model = ResNet18(input_shape=(224,224,3), include_top=False, classes=2)\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "predictions = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(predictions)\n",
    "\n",
    "model = Model(inputs=[base_model.input], outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining f1 function\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining optimizer\n",
    "sgd = optimizers.SGD(lr=0.001, decay=0.0, momentum=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters for tunning\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "#               optimizer=Adam(lr=0.001),\n",
    "              metrics=['acc',f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining batch sizes\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining sample sizes \n",
    "nb_samples_train = len(train_generator.filenames)\n",
    "nb_samples_val= len(val_generator.filenames)\n",
    "nb_samples_test = len(test_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate=0.001\n",
    "    drop=0.5\n",
    "    epochs_drop=10\n",
    "    lrate=initial_lrate*math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate callback\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3043/3042 [==============================] - 1441s 473ms/step - loss: 0.6666 - acc: 0.5840 - f1: 0.4740 - val_loss: 0.6656 - val_acc: 0.5945 - val_f1: 0.4742\n",
      "Epoch 2/100\n",
      "3043/3042 [==============================] - 878s 288ms/step - loss: 0.6637 - acc: 0.5904 - f1: 0.4738 - val_loss: 0.6621 - val_acc: 0.6065 - val_f1: 0.4711\n",
      "Epoch 3/100\n",
      "3043/3042 [==============================] - 878s 289ms/step - loss: 0.6631 - acc: 0.5915 - f1: 0.4725 - val_loss: 0.6654 - val_acc: 0.5965 - val_f1: 0.4680\n",
      "Epoch 4/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6602 - acc: 0.5959 - f1: 0.4730 - val_loss: 0.6651 - val_acc: 0.6055 - val_f1: 0.4772\n",
      "Epoch 5/100\n",
      "3043/3042 [==============================] - 884s 290ms/step - loss: 0.6618 - acc: 0.5944 - f1: 0.4740 - val_loss: 0.6627 - val_acc: 0.6045 - val_f1: 0.4682\n",
      "Epoch 6/100\n",
      "3043/3042 [==============================] - 884s 290ms/step - loss: 0.6592 - acc: 0.5992 - f1: 0.4717 - val_loss: 0.6663 - val_acc: 0.6010 - val_f1: 0.4687\n",
      "Epoch 7/100\n",
      "3043/3042 [==============================] - 874s 287ms/step - loss: 0.6582 - acc: 0.5992 - f1: 0.4722 - val_loss: 0.6576 - val_acc: 0.6100 - val_f1: 0.4683\n",
      "Epoch 8/100\n",
      "3043/3042 [==============================] - 881s 290ms/step - loss: 0.6576 - acc: 0.6020 - f1: 0.4746 - val_loss: 0.6614 - val_acc: 0.6095 - val_f1: 0.4693\n",
      "Epoch 9/100\n",
      "3043/3042 [==============================] - 877s 288ms/step - loss: 0.6572 - acc: 0.6014 - f1: 0.4721 - val_loss: 0.6629 - val_acc: 0.6055 - val_f1: 0.4703\n",
      "Epoch 10/100\n",
      "3043/3042 [==============================] - 875s 287ms/step - loss: 0.6571 - acc: 0.6052 - f1: 0.4745 - val_loss: 0.6540 - val_acc: 0.6115 - val_f1: 0.4740\n",
      "Epoch 11/100\n",
      "3043/3042 [==============================] - 878s 289ms/step - loss: 0.6562 - acc: 0.6062 - f1: 0.4734 - val_loss: 0.6574 - val_acc: 0.6180 - val_f1: 0.4727\n",
      "Epoch 12/100\n",
      "3043/3042 [==============================] - 875s 288ms/step - loss: 0.6550 - acc: 0.6093 - f1: 0.4730 - val_loss: 0.6567 - val_acc: 0.6125 - val_f1: 0.4768\n",
      "Epoch 13/100\n",
      "3043/3042 [==============================] - 884s 291ms/step - loss: 0.6560 - acc: 0.6068 - f1: 0.4752 - val_loss: 0.6594 - val_acc: 0.6045 - val_f1: 0.4628\n",
      "Epoch 14/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6560 - acc: 0.6060 - f1: 0.4731 - val_loss: 0.6546 - val_acc: 0.6185 - val_f1: 0.4746\n",
      "Epoch 15/100\n",
      "3043/3042 [==============================] - 884s 290ms/step - loss: 0.6540 - acc: 0.6098 - f1: 0.4736 - val_loss: 0.6549 - val_acc: 0.6100 - val_f1: 0.4697\n",
      "Epoch 16/100\n",
      "3043/3042 [==============================] - 885s 291ms/step - loss: 0.6535 - acc: 0.6112 - f1: 0.4754 - val_loss: 0.6543 - val_acc: 0.6085 - val_f1: 0.4746\n",
      "Epoch 17/100\n",
      "3043/3042 [==============================] - 889s 292ms/step - loss: 0.6544 - acc: 0.6093 - f1: 0.4715 - val_loss: 0.6581 - val_acc: 0.6085 - val_f1: 0.4720\n",
      "Epoch 18/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6536 - acc: 0.6102 - f1: 0.4751 - val_loss: 0.6526 - val_acc: 0.6225 - val_f1: 0.4716\n",
      "Epoch 19/100\n",
      "3043/3042 [==============================] - 882s 290ms/step - loss: 0.6533 - acc: 0.6118 - f1: 0.4738 - val_loss: 0.6518 - val_acc: 0.6175 - val_f1: 0.4759\n",
      "Epoch 20/100\n",
      "3043/3042 [==============================] - 879s 289ms/step - loss: 0.6517 - acc: 0.6123 - f1: 0.4759 - val_loss: 0.6536 - val_acc: 0.6200 - val_f1: 0.4700\n",
      "Epoch 21/100\n",
      "3043/3042 [==============================] - 882s 290ms/step - loss: 0.6512 - acc: 0.6150 - f1: 0.4748 - val_loss: 0.6499 - val_acc: 0.6225 - val_f1: 0.4723\n",
      "Epoch 22/100\n",
      "3043/3042 [==============================] - 889s 292ms/step - loss: 0.6510 - acc: 0.6166 - f1: 0.4734 - val_loss: 0.6529 - val_acc: 0.6065 - val_f1: 0.4706\n",
      "Epoch 23/100\n",
      "3043/3042 [==============================] - 888s 292ms/step - loss: 0.6512 - acc: 0.6150 - f1: 0.4752 - val_loss: 0.6528 - val_acc: 0.6225 - val_f1: 0.4684\n",
      "Epoch 24/100\n",
      "3043/3042 [==============================] - 891s 293ms/step - loss: 0.6503 - acc: 0.6161 - f1: 0.4748 - val_loss: 0.6549 - val_acc: 0.6215 - val_f1: 0.4784\n",
      "Epoch 25/100\n",
      "3043/3042 [==============================] - 886s 291ms/step - loss: 0.6515 - acc: 0.6133 - f1: 0.4744 - val_loss: 0.6494 - val_acc: 0.6155 - val_f1: 0.4703\n",
      "Epoch 26/100\n",
      "3043/3042 [==============================] - 884s 291ms/step - loss: 0.6505 - acc: 0.6172 - f1: 0.4742 - val_loss: 0.6536 - val_acc: 0.6185 - val_f1: 0.4718\n",
      "Epoch 27/100\n",
      "3043/3042 [==============================] - 886s 291ms/step - loss: 0.6489 - acc: 0.6184 - f1: 0.4752 - val_loss: 0.6472 - val_acc: 0.6220 - val_f1: 0.4715\n",
      "Epoch 28/100\n",
      "3043/3042 [==============================] - 885s 291ms/step - loss: 0.6493 - acc: 0.6156 - f1: 0.4748 - val_loss: 0.6521 - val_acc: 0.6235 - val_f1: 0.4700\n",
      "Epoch 29/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6503 - acc: 0.6159 - f1: 0.4762 - val_loss: 0.6503 - val_acc: 0.6285 - val_f1: 0.4724\n",
      "Epoch 30/100\n",
      "3043/3042 [==============================] - 879s 289ms/step - loss: 0.6501 - acc: 0.6181 - f1: 0.4755 - val_loss: 0.6480 - val_acc: 0.6330 - val_f1: 0.4800\n",
      "Epoch 31/100\n",
      "3043/3042 [==============================] - 890s 292ms/step - loss: 0.6470 - acc: 0.6238 - f1: 0.4749 - val_loss: 0.6476 - val_acc: 0.6200 - val_f1: 0.4701\n",
      "Epoch 32/100\n",
      "3043/3042 [==============================] - 877s 288ms/step - loss: 0.6499 - acc: 0.6174 - f1: 0.4755 - val_loss: 0.6515 - val_acc: 0.6185 - val_f1: 0.4688\n",
      "Epoch 33/100\n",
      "3043/3042 [==============================] - 865s 284ms/step - loss: 0.6472 - acc: 0.6198 - f1: 0.4751 - val_loss: 0.6501 - val_acc: 0.6150 - val_f1: 0.4752\n",
      "Epoch 34/100\n",
      "3043/3042 [==============================] - 869s 286ms/step - loss: 0.6500 - acc: 0.6155 - f1: 0.4747 - val_loss: 0.6470 - val_acc: 0.6315 - val_f1: 0.4731\n",
      "Epoch 35/100\n",
      "3043/3042 [==============================] - 878s 289ms/step - loss: 0.6487 - acc: 0.6200 - f1: 0.4760 - val_loss: 0.6464 - val_acc: 0.6240 - val_f1: 0.4737\n",
      "Epoch 36/100\n",
      "3043/3042 [==============================] - 873s 287ms/step - loss: 0.6468 - acc: 0.6236 - f1: 0.4751 - val_loss: 0.6449 - val_acc: 0.6290 - val_f1: 0.4757\n",
      "Epoch 37/100\n",
      "3043/3042 [==============================] - 877s 288ms/step - loss: 0.6481 - acc: 0.6194 - f1: 0.4755 - val_loss: 0.6535 - val_acc: 0.6130 - val_f1: 0.4779\n",
      "Epoch 38/100\n",
      "3043/3042 [==============================] - 881s 290ms/step - loss: 0.6469 - acc: 0.6234 - f1: 0.4753 - val_loss: 0.6514 - val_acc: 0.6255 - val_f1: 0.4711\n",
      "Epoch 39/100\n",
      "3043/3042 [==============================] - 884s 290ms/step - loss: 0.6471 - acc: 0.6215 - f1: 0.4760 - val_loss: 0.6459 - val_acc: 0.6275 - val_f1: 0.4700\n",
      "Epoch 40/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6460 - acc: 0.6204 - f1: 0.4762 - val_loss: 0.6503 - val_acc: 0.6240 - val_f1: 0.4718\n",
      "Epoch 41/100\n",
      "3043/3042 [==============================] - 880s 289ms/step - loss: 0.6473 - acc: 0.6230 - f1: 0.4754 - val_loss: 0.6437 - val_acc: 0.6280 - val_f1: 0.4733\n",
      "Epoch 42/100\n",
      "3043/3042 [==============================] - 880s 289ms/step - loss: 0.6454 - acc: 0.6255 - f1: 0.4752 - val_loss: 0.6502 - val_acc: 0.6240 - val_f1: 0.4718\n",
      "Epoch 43/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6481 - acc: 0.6202 - f1: 0.4763 - val_loss: 0.6462 - val_acc: 0.6305 - val_f1: 0.4731\n",
      "Epoch 44/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6475 - acc: 0.6224 - f1: 0.4764 - val_loss: 0.6457 - val_acc: 0.6275 - val_f1: 0.4697\n",
      "Epoch 45/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6473 - acc: 0.6200 - f1: 0.4757 - val_loss: 0.6475 - val_acc: 0.6240 - val_f1: 0.4777\n",
      "Epoch 46/100\n",
      "3043/3042 [==============================] - 877s 288ms/step - loss: 0.6475 - acc: 0.6224 - f1: 0.4741 - val_loss: 0.6484 - val_acc: 0.6235 - val_f1: 0.4736\n",
      "Epoch 47/100\n",
      "3043/3042 [==============================] - 885s 291ms/step - loss: 0.6462 - acc: 0.6221 - f1: 0.4767 - val_loss: 0.6477 - val_acc: 0.6345 - val_f1: 0.4712\n",
      "Epoch 48/100\n",
      "3043/3042 [==============================] - 881s 289ms/step - loss: 0.6471 - acc: 0.6228 - f1: 0.4752 - val_loss: 0.6509 - val_acc: 0.6230 - val_f1: 0.4709\n",
      "Epoch 49/100\n",
      "3043/3042 [==============================] - 881s 289ms/step - loss: 0.6472 - acc: 0.6204 - f1: 0.4765 - val_loss: 0.6482 - val_acc: 0.6175 - val_f1: 0.4735\n",
      "Epoch 50/100\n",
      "3043/3042 [==============================] - 873s 287ms/step - loss: 0.6479 - acc: 0.6194 - f1: 0.4758 - val_loss: 0.6452 - val_acc: 0.6320 - val_f1: 0.4746\n",
      "Epoch 51/100\n",
      "3043/3042 [==============================] - 878s 289ms/step - loss: 0.6462 - acc: 0.6202 - f1: 0.4757 - val_loss: 0.6447 - val_acc: 0.6340 - val_f1: 0.4708\n",
      "Epoch 52/100\n",
      "3043/3042 [==============================] - 877s 288ms/step - loss: 0.6472 - acc: 0.6195 - f1: 0.4768 - val_loss: 0.6477 - val_acc: 0.6195 - val_f1: 0.4785\n",
      "Epoch 53/100\n",
      "3043/3042 [==============================] - 875s 287ms/step - loss: 0.6466 - acc: 0.6219 - f1: 0.4746 - val_loss: 0.6431 - val_acc: 0.6275 - val_f1: 0.4714\n",
      "Epoch 54/100\n",
      "3043/3042 [==============================] - 875s 287ms/step - loss: 0.6468 - acc: 0.6205 - f1: 0.4774 - val_loss: 0.6474 - val_acc: 0.6270 - val_f1: 0.4765\n",
      "Epoch 55/100\n",
      "3043/3042 [==============================] - 877s 288ms/step - loss: 0.6472 - acc: 0.6213 - f1: 0.4748 - val_loss: 0.6509 - val_acc: 0.6200 - val_f1: 0.4750\n",
      "Epoch 56/100\n",
      "3043/3042 [==============================] - 874s 287ms/step - loss: 0.6475 - acc: 0.6201 - f1: 0.4760 - val_loss: 0.6480 - val_acc: 0.6225 - val_f1: 0.4730\n",
      "Epoch 57/100\n",
      "3043/3042 [==============================] - 873s 287ms/step - loss: 0.6464 - acc: 0.6226 - f1: 0.4760 - val_loss: 0.6439 - val_acc: 0.6295 - val_f1: 0.4744\n",
      "Epoch 58/100\n",
      "3043/3042 [==============================] - 869s 286ms/step - loss: 0.6474 - acc: 0.6219 - f1: 0.4751 - val_loss: 0.6407 - val_acc: 0.6315 - val_f1: 0.4738\n",
      "Epoch 59/100\n",
      "3043/3042 [==============================] - 874s 287ms/step - loss: 0.6463 - acc: 0.6241 - f1: 0.4779 - val_loss: 0.6468 - val_acc: 0.6325 - val_f1: 0.4804\n",
      "Epoch 60/100\n",
      "3043/3042 [==============================] - 882s 290ms/step - loss: 0.6474 - acc: 0.6204 - f1: 0.4748 - val_loss: 0.6490 - val_acc: 0.6370 - val_f1: 0.4722\n",
      "Epoch 61/100\n",
      "3043/3042 [==============================] - 880s 289ms/step - loss: 0.6467 - acc: 0.6210 - f1: 0.4769 - val_loss: 0.6436 - val_acc: 0.6270 - val_f1: 0.4698\n",
      "Epoch 62/100\n",
      "3043/3042 [==============================] - 882s 290ms/step - loss: 0.6455 - acc: 0.6258 - f1: 0.4760 - val_loss: 0.6466 - val_acc: 0.6300 - val_f1: 0.4734\n",
      "Epoch 63/100\n",
      "3043/3042 [==============================] - 888s 292ms/step - loss: 0.6495 - acc: 0.6186 - f1: 0.4766 - val_loss: 0.6467 - val_acc: 0.6315 - val_f1: 0.4718\n",
      "Epoch 64/100\n",
      "3043/3042 [==============================] - 885s 291ms/step - loss: 0.6449 - acc: 0.6263 - f1: 0.4754 - val_loss: 0.6487 - val_acc: 0.6215 - val_f1: 0.4709\n",
      "Epoch 65/100\n",
      "3043/3042 [==============================] - 884s 291ms/step - loss: 0.6488 - acc: 0.6195 - f1: 0.4753 - val_loss: 0.6439 - val_acc: 0.6310 - val_f1: 0.4750\n",
      "Epoch 66/100\n",
      "3043/3042 [==============================] - 884s 291ms/step - loss: 0.6457 - acc: 0.6226 - f1: 0.4778 - val_loss: 0.6408 - val_acc: 0.6375 - val_f1: 0.4732\n",
      "Epoch 67/100\n",
      "3043/3042 [==============================] - 874s 287ms/step - loss: 0.6469 - acc: 0.6209 - f1: 0.4761 - val_loss: 0.6503 - val_acc: 0.6205 - val_f1: 0.4722\n",
      "Epoch 68/100\n",
      "3043/3042 [==============================] - 888s 292ms/step - loss: 0.6465 - acc: 0.6238 - f1: 0.4762 - val_loss: 0.6468 - val_acc: 0.6195 - val_f1: 0.4714\n",
      "Epoch 69/100\n",
      "3043/3042 [==============================] - 885s 291ms/step - loss: 0.6460 - acc: 0.6214 - f1: 0.4768 - val_loss: 0.6474 - val_acc: 0.6295 - val_f1: 0.4732\n",
      "Epoch 70/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6475 - acc: 0.6220 - f1: 0.4767 - val_loss: 0.6470 - val_acc: 0.6320 - val_f1: 0.4792\n",
      "Epoch 71/100\n",
      "3043/3042 [==============================] - 880s 289ms/step - loss: 0.6474 - acc: 0.6204 - f1: 0.4745 - val_loss: 0.6460 - val_acc: 0.6300 - val_f1: 0.4734\n",
      "Epoch 72/100\n",
      "3043/3042 [==============================] - 879s 289ms/step - loss: 0.6471 - acc: 0.6209 - f1: 0.4747 - val_loss: 0.6455 - val_acc: 0.6320 - val_f1: 0.4786\n",
      "Epoch 73/100\n",
      "3043/3042 [==============================] - 875s 288ms/step - loss: 0.6460 - acc: 0.6245 - f1: 0.4780 - val_loss: 0.6511 - val_acc: 0.6155 - val_f1: 0.4710\n",
      "Epoch 74/100\n",
      "3043/3042 [==============================] - 881s 290ms/step - loss: 0.6456 - acc: 0.6233 - f1: 0.4769 - val_loss: 0.6498 - val_acc: 0.6210 - val_f1: 0.4712\n",
      "Epoch 75/100\n",
      "3043/3042 [==============================] - 881s 290ms/step - loss: 0.6458 - acc: 0.6237 - f1: 0.4757 - val_loss: 0.6494 - val_acc: 0.6230 - val_f1: 0.4699\n",
      "Epoch 76/100\n",
      "3043/3042 [==============================] - 889s 292ms/step - loss: 0.6463 - acc: 0.6214 - f1: 0.4770 - val_loss: 0.6452 - val_acc: 0.6265 - val_f1: 0.4763\n",
      "Epoch 77/100\n",
      "3043/3042 [==============================] - 884s 290ms/step - loss: 0.6446 - acc: 0.6250 - f1: 0.4756 - val_loss: 0.6490 - val_acc: 0.6220 - val_f1: 0.4755\n",
      "Epoch 78/100\n",
      "3043/3042 [==============================] - 881s 290ms/step - loss: 0.6469 - acc: 0.6218 - f1: 0.4756 - val_loss: 0.6455 - val_acc: 0.6320 - val_f1: 0.4697\n",
      "Epoch 79/100\n",
      "3043/3042 [==============================] - 876s 288ms/step - loss: 0.6456 - acc: 0.6254 - f1: 0.4767 - val_loss: 0.6411 - val_acc: 0.6235 - val_f1: 0.4770\n",
      "Epoch 80/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6444 - acc: 0.6249 - f1: 0.4747 - val_loss: 0.6499 - val_acc: 0.6230 - val_f1: 0.4700\n",
      "Epoch 81/100\n",
      "3043/3042 [==============================] - 890s 293ms/step - loss: 0.6483 - acc: 0.6192 - f1: 0.4784 - val_loss: 0.6449 - val_acc: 0.6275 - val_f1: 0.4745\n",
      "Epoch 82/100\n",
      "3043/3042 [==============================] - 880s 289ms/step - loss: 0.6468 - acc: 0.6237 - f1: 0.4764 - val_loss: 0.6475 - val_acc: 0.6260 - val_f1: 0.4695\n",
      "Epoch 83/100\n",
      "3043/3042 [==============================] - 881s 290ms/step - loss: 0.6460 - acc: 0.6252 - f1: 0.4752 - val_loss: 0.6445 - val_acc: 0.6290 - val_f1: 0.4786\n",
      "Epoch 84/100\n",
      "3043/3042 [==============================] - 879s 289ms/step - loss: 0.6477 - acc: 0.6202 - f1: 0.4755 - val_loss: 0.6469 - val_acc: 0.6295 - val_f1: 0.4711\n",
      "Epoch 85/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6490 - acc: 0.6173 - f1: 0.4788 - val_loss: 0.6394 - val_acc: 0.6250 - val_f1: 0.4709\n",
      "Epoch 86/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6449 - acc: 0.6253 - f1: 0.4727 - val_loss: 0.6512 - val_acc: 0.6145 - val_f1: 0.4722\n",
      "Epoch 87/100\n",
      "3043/3042 [==============================] - 888s 292ms/step - loss: 0.6478 - acc: 0.6210 - f1: 0.4769 - val_loss: 0.6504 - val_acc: 0.6245 - val_f1: 0.4775\n",
      "Epoch 88/100\n",
      "3043/3042 [==============================] - 884s 290ms/step - loss: 0.6444 - acc: 0.6255 - f1: 0.4777 - val_loss: 0.6406 - val_acc: 0.6305 - val_f1: 0.4697\n",
      "Epoch 89/100\n",
      "3043/3042 [==============================] - 880s 289ms/step - loss: 0.6481 - acc: 0.6201 - f1: 0.4774 - val_loss: 0.6465 - val_acc: 0.6315 - val_f1: 0.4758\n",
      "Epoch 90/100\n",
      "3043/3042 [==============================] - 878s 289ms/step - loss: 0.6458 - acc: 0.6242 - f1: 0.4751 - val_loss: 0.6466 - val_acc: 0.6315 - val_f1: 0.4787\n",
      "Epoch 91/100\n",
      "3043/3042 [==============================] - 882s 290ms/step - loss: 0.6451 - acc: 0.6231 - f1: 0.4756 - val_loss: 0.6479 - val_acc: 0.6235 - val_f1: 0.4768\n",
      "Epoch 92/100\n",
      "3043/3042 [==============================] - 886s 291ms/step - loss: 0.6478 - acc: 0.6204 - f1: 0.4772 - val_loss: 0.6473 - val_acc: 0.6300 - val_f1: 0.4748\n",
      "Epoch 93/100\n",
      "3043/3042 [==============================] - 888s 292ms/step - loss: 0.6460 - acc: 0.6219 - f1: 0.4755 - val_loss: 0.6420 - val_acc: 0.6325 - val_f1: 0.4726\n",
      "Epoch 94/100\n",
      "3043/3042 [==============================] - 886s 291ms/step - loss: 0.6455 - acc: 0.6230 - f1: 0.4755 - val_loss: 0.6494 - val_acc: 0.6175 - val_f1: 0.4702\n",
      "Epoch 95/100\n",
      "3043/3042 [==============================] - 887s 291ms/step - loss: 0.6473 - acc: 0.6197 - f1: 0.4790 - val_loss: 0.6444 - val_acc: 0.6225 - val_f1: 0.4733\n",
      "Epoch 96/100\n",
      "3043/3042 [==============================] - 889s 292ms/step - loss: 0.6465 - acc: 0.6203 - f1: 0.4742 - val_loss: 0.6434 - val_acc: 0.6415 - val_f1: 0.4777\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3043/3042 [==============================] - 886s 291ms/step - loss: 0.6461 - acc: 0.6231 - f1: 0.4755 - val_loss: 0.6439 - val_acc: 0.6280 - val_f1: 0.4769\n",
      "Epoch 98/100\n",
      "3043/3042 [==============================] - 886s 291ms/step - loss: 0.6471 - acc: 0.6225 - f1: 0.4764 - val_loss: 0.6497 - val_acc: 0.6225 - val_f1: 0.4732\n",
      "Epoch 99/100\n",
      "3043/3042 [==============================] - 883s 290ms/step - loss: 0.6458 - acc: 0.6215 - f1: 0.4752 - val_loss: 0.6464 - val_acc: 0.6265 - val_f1: 0.4710\n",
      "Epoch 100/100\n",
      "3043/3042 [==============================] - 882s 290ms/step - loss: 0.6474 - acc: 0.6189 - f1: 0.4755 - val_loss: 0.6479 - val_acc: 0.6235 - val_f1: 0.4723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e18c7ee10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_samples_train/batch_size,\n",
    "        epochs=100,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=nb_samples_val/batch_size,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6216216216216216"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final test\n",
    "y_prob = model.predict_generator(test_generator,steps = nb_samples_test/64,use_multiprocessing=True)\n",
    "y_true=test_generator.labels\n",
    "y_pred=y_prob.argmax(1)\n",
    "final_f1=metrics.f1_score(y_true, y_pred , average='binary')\n",
    "final_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model and weights\n",
    "model.save('model.h5')\n",
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model and weights\n",
    "model = load_model('model.h5',custom_objects={'f1': f1})\n",
    "model.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate avarage percision\n",
    "average_precision = average_precision_score(validation_generator.classes, [x[1] for x in full_pred])\n",
    "print('Average precision-recall score for full model: {0:0.10f}'.format(average_precision_full))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
