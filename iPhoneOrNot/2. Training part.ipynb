{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iPhone case (Neural Network training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sofia Shchipinskaya*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short plan of training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Transforming the data\n",
    "2. Installing ResNet18\n",
    "3. Building the model (defining parameters, ect.)\n",
    "4. Running the model\n",
    "5. Converting the model\n",
    "6. Checking the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import resnet50, inception_v3, vgg16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from classification_models.resnet import ResNet18\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.contrib import lite\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating random transformation\n",
    "val_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 48684 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# creating data loaders\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        'full dataset/val',  \n",
    "        target_size=(224, 224),  \n",
    "        batch_size=64,\n",
    "        class_mode='binary')  \n",
    "\n",
    "train_generator = val_datagen.flow_from_directory(\n",
    "        'full dataset/train',  \n",
    "        target_size=(224, 224), \n",
    "        batch_size=64,\n",
    "        class_mode='binary')  \n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "        'full dataset/test',  \n",
    "        target_size=(224, 224), \n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        class_mode='binary')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'An': 0, 'Ip': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the neural network and running it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/classification_models.git\n",
      "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-l_xdgcmp\n",
      "Requirement already satisfied (use --upgrade to upgrade): image-classifiers==0.2.2 from git+https://github.com/qubvel/classification_models.git in ./anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: keras>=2.1.0 in ./anaconda3/lib/python3.6/site-packages (from image-classifiers==0.2.2) (2.2.4)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (5.1)\n",
      "Requirement already satisfied: h5py in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.16.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.0.8)\n",
      "Building wheels for collected packages: image-classifiers\n",
      "  Building wheel for image-classifiers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-lf4diab6/wheels/de/2b/fd/29a6d33edb8c28bc7d94e95ea1d39c9a218ac500a3cfb1b197\n",
      "Successfully built image-classifiers\n"
     ]
    }
   ],
   "source": [
    "# installing ResNet18\n",
    "!pip install git+https://github.com/qubvel/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shipinskaya_sofi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# building the model\n",
    "model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=True)\n",
    "model.layers.pop()\n",
    "last = model.layers[-1].output\n",
    "x = Dense(2, activation=\"softmax\")(last)\n",
    "model = Model(model.input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "The next step is to define an optimizer. I tried Adam and SGD optimizers, however, in this version of the model i decided to use Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining optimizer\n",
    "# sgd = optimizers.SGD(lr=0.001, decay=0.0, momentum=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters for tunning\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer=sgd,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer=sgd,\n",
    "# #               optimizer=Adam(lr=0.001),\n",
    "#               metrics=['acc',f1])\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining batch sizes\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining sample sizes \n",
    "nb_samples_train = len(train_generator.filenames)\n",
    "nb_samples_val= len(val_generator.filenames)\n",
    "nb_samples_test = len(test_generator.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "I decided to use learing rate schedule, so there are some steps to set it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate=0.001\n",
    "    drop=0.5\n",
    "    epochs_drop=10\n",
    "    lrate=initial_lrate*math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate callback\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "The next part is the part of model training. As you can see, I chose to train only 2 epochs. In the previous version of training part I set 100 epochs and trained them all (you can see that file in my repo). Due to techical reasons (poor Internet connection and some problems with Google Cloud GPU) I had no time to train the model (previous model took 24h to train with epoch=100 and batch_size=16). In this version I chose epoch=2 and batch_size=64. So, to upload my model on time, I decided to make quite \"fast\" calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shipinskaya_sofi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "761/760 [==============================] - 645s 848ms/step - loss: 0.4835 - acc: 0.7777 - val_loss: 0.7287 - val_acc: 0.7315\n",
      "Epoch 2/2\n",
      "761/760 [==============================] - 635s 835ms/step - loss: 0.3561 - acc: 0.8365 - val_loss: 0.5692 - val_acc: 0.7740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f51504146a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_samples_train/batch_size,\n",
    "        epochs=2,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=nb_samples_val/batch_size,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model and weights\n",
    "model.save('my_model2.h5')\n",
    "model.save_weights('my_weights2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "As GitHub doesn't allow to upload files of more than 100Mb, I converted the model to decrease the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shipinskaya_sofi/anaconda3/lib/python3.6/site-packages/tensorflow/lite/python/lite.py:591: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /home/shipinskaya_sofi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 100 variables.\n",
      "INFO:tensorflow:Converted 100 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46791100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting keras model to tflite model\n",
    "converter = lite.TFLiteConverter.from_keras_model_file('my_model2.h5')\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function for loading and rescaling images\n",
    "def load_image(img_path):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_tensor = image.img_to_array(img)                    \n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         \n",
    "    img_tensor /= 255.\n",
    "    \n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading converted model, setting input and output\n",
    "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing predictions\n",
    "pred = []\n",
    "for subdir, dirs, files in os.walk('full dataset/test'):\n",
    "    for file in files:\n",
    "        input_data = load_image(os.path.join(subdir, file))\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        pred.append(output_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision is: 0.9172811585\n"
     ]
    }
   ],
   "source": [
    "# calculating avarage percision\n",
    "average_precision = average_precision_score(test_generator.classes, [x[1] for x in pred])\n",
    "print('Average precision is: {0:0.10f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "Even if i trained here only 2 epochs, the average precision is quite high (91.72%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
