{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iPhone case (Neural Network training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sofia Shchipinskaya*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short plan of training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Transforming the data\n",
    "2. Installing ResNet18\n",
    "3. Building the model (defining parameters, ect.)\n",
    "4. Running the model\n",
    "5. Converting the model\n",
    "6. Checking the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import resnet50, inception_v3, vgg16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from classification_models.resnet import ResNet18\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.contrib import lite\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating random transformation\n",
    "val_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 48684 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# creating data loaders\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        'full dataset/val',  \n",
    "        target_size=(224, 224),  \n",
    "        batch_size=64,\n",
    "        class_mode='binary')  \n",
    "\n",
    "train_generator = val_datagen.flow_from_directory(\n",
    "        'full dataset/train',  \n",
    "        target_size=(224, 224), \n",
    "        batch_size=64,\n",
    "        class_mode='binary')  \n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "        'full dataset/test',  \n",
    "        target_size=(224, 224), \n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        class_mode='binary')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'An': 0, 'Ip': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the neural network and running it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/classification_models.git\n",
      "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-vjjjooc3\n",
      "Requirement already satisfied (use --upgrade to upgrade): image-classifiers==0.2.2 from git+https://github.com/qubvel/classification_models.git in ./anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: keras>=2.1.0 in ./anaconda3/lib/python3.6/site-packages (from image-classifiers==0.2.2) (2.2.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.14 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.2.1)\n",
      "Requirement already satisfied: h5py in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (5.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in ./anaconda3/lib/python3.6/site-packages (from keras>=2.1.0->image-classifiers==0.2.2) (1.0.8)\n",
      "Building wheels for collected packages: image-classifiers\n",
      "  Building wheel for image-classifiers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-p2wp9oq5/wheels/de/2b/fd/29a6d33edb8c28bc7d94e95ea1d39c9a218ac500a3cfb1b197\n",
      "Successfully built image-classifiers\n"
     ]
    }
   ],
   "source": [
    "# installing ResNet18\n",
    "!pip install git+https://github.com/qubvel/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# building the model\n",
    "model = ResNet18(input_shape=(224,224,3), weights='imagenet', include_top=True)\n",
    "model.layers.pop()\n",
    "last = model.layers[-1].output\n",
    "x = Dense(2, activation=\"softmax\")(last)\n",
    "model = Model(model.input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "The next step is to define an optimizer. I tried Adam and SGD optimizers, however, in this version of the model i decided to use Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining optimizer\n",
    "# sgd = optimizers.SGD(lr=0.001, decay=0.0, momentum=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters for tunning\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer=sgd,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer=sgd,\n",
    "# #               optimizer=Adam(lr=0.001),\n",
    "#               metrics=['acc',f1])\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining batch sizes\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining sample sizes \n",
    "nb_samples_train = len(train_generator.filenames)\n",
    "nb_samples_val= len(val_generator.filenames)\n",
    "nb_samples_test = len(test_generator.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "I decided to use learing rate schedule, so there are some steps to set it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate=0.001\n",
    "    drop=0.5\n",
    "    epochs_drop=10\n",
    "    lrate=initial_lrate*math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate callback\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "The next part is the part of model training. As you can see, I chose to train 80 epochs. In the previous version of training part I set 100 epochs and trained them all (you can see that file in my repo). Due to techical reasons (poor Internet connection and some problems with Google Cloud GPU) I had no time to train the model (previous model took 24h to train with epoch=100 and batch_size=16). In this version I chose epoch=80 and batch_size=64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "761/760 [==============================] - 645s 847ms/step - loss: 0.5369 - acc: 0.7555 - val_loss: 0.5357 - val_acc: 0.7525\n",
      "Epoch 2/80\n",
      "761/760 [==============================] - 638s 839ms/step - loss: 0.3349 - acc: 0.8470 - val_loss: 0.5139 - val_acc: 0.8015\n",
      "Epoch 3/80\n",
      "761/760 [==============================] - 640s 840ms/step - loss: 0.2980 - acc: 0.8670 - val_loss: 0.3536 - val_acc: 0.8345\n",
      "Epoch 4/80\n",
      "761/760 [==============================] - 637s 838ms/step - loss: 0.2728 - acc: 0.8770 - val_loss: 0.4252 - val_acc: 0.8245\n",
      "Epoch 5/80\n",
      "761/760 [==============================] - 637s 837ms/step - loss: 0.2504 - acc: 0.8892 - val_loss: 0.2892 - val_acc: 0.8705\n",
      "Epoch 6/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.2418 - acc: 0.8947 - val_loss: 0.3044 - val_acc: 0.8570\n",
      "Epoch 7/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.2290 - acc: 0.9002 - val_loss: 0.3173 - val_acc: 0.8555\n",
      "Epoch 8/80\n",
      "761/760 [==============================] - 638s 838ms/step - loss: 0.2142 - acc: 0.9063 - val_loss: 0.2653 - val_acc: 0.8945\n",
      "Epoch 9/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.2052 - acc: 0.9104 - val_loss: 0.3819 - val_acc: 0.8720\n",
      "Epoch 10/80\n",
      "761/760 [==============================] - 641s 843ms/step - loss: 0.1776 - acc: 0.9239 - val_loss: 0.2058 - val_acc: 0.9125\n",
      "Epoch 11/80\n",
      "761/760 [==============================] - 634s 833ms/step - loss: 0.1597 - acc: 0.9312 - val_loss: 0.1888 - val_acc: 0.9195\n",
      "Epoch 12/80\n",
      "761/760 [==============================] - 633s 832ms/step - loss: 0.1539 - acc: 0.9329 - val_loss: 0.1972 - val_acc: 0.9130\n",
      "Epoch 13/80\n",
      "761/760 [==============================] - 635s 834ms/step - loss: 0.1449 - acc: 0.9385 - val_loss: 0.1693 - val_acc: 0.9315\n",
      "Epoch 14/80\n",
      "761/760 [==============================] - 637s 837ms/step - loss: 0.1377 - acc: 0.9417 - val_loss: 0.1772 - val_acc: 0.9235\n",
      "Epoch 15/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.1352 - acc: 0.9428 - val_loss: 0.1719 - val_acc: 0.9235\n",
      "Epoch 16/80\n",
      "761/760 [==============================] - 636s 835ms/step - loss: 0.1299 - acc: 0.9454 - val_loss: 0.1572 - val_acc: 0.9345\n",
      "Epoch 17/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.1288 - acc: 0.9459 - val_loss: 0.1834 - val_acc: 0.9195\n",
      "Epoch 18/80\n",
      "761/760 [==============================] - 641s 843ms/step - loss: 0.1229 - acc: 0.9484 - val_loss: 0.1629 - val_acc: 0.9330\n",
      "Epoch 19/80\n",
      "761/760 [==============================] - 642s 844ms/step - loss: 0.1188 - acc: 0.9521 - val_loss: 0.1706 - val_acc: 0.9325\n",
      "Epoch 20/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.1016 - acc: 0.9586 - val_loss: 0.1485 - val_acc: 0.9405\n",
      "Epoch 21/80\n",
      "761/760 [==============================] - 641s 842ms/step - loss: 0.0917 - acc: 0.9624 - val_loss: 0.1448 - val_acc: 0.9470\n",
      "Epoch 22/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.0883 - acc: 0.9633 - val_loss: 0.1500 - val_acc: 0.9410\n",
      "Epoch 23/80\n",
      "761/760 [==============================] - 638s 838ms/step - loss: 0.0858 - acc: 0.9650 - val_loss: 0.1534 - val_acc: 0.9475\n",
      "Epoch 24/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.0833 - acc: 0.9662 - val_loss: 0.1660 - val_acc: 0.9380\n",
      "Epoch 25/80\n",
      "761/760 [==============================] - 639s 839ms/step - loss: 0.0821 - acc: 0.9662 - val_loss: 0.1527 - val_acc: 0.9480\n",
      "Epoch 26/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.0800 - acc: 0.9673 - val_loss: 0.1447 - val_acc: 0.9430\n",
      "Epoch 27/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.0762 - acc: 0.9698 - val_loss: 0.1495 - val_acc: 0.9435\n",
      "Epoch 28/80\n",
      "761/760 [==============================] - 641s 842ms/step - loss: 0.0749 - acc: 0.9702 - val_loss: 0.1572 - val_acc: 0.9415\n",
      "Epoch 29/80\n",
      "761/760 [==============================] - 641s 843ms/step - loss: 0.0720 - acc: 0.9715 - val_loss: 0.1513 - val_acc: 0.9500\n",
      "Epoch 30/80\n",
      "761/760 [==============================] - 641s 843ms/step - loss: 0.0612 - acc: 0.9765 - val_loss: 0.1832 - val_acc: 0.9455\n",
      "Epoch 31/80\n",
      "761/760 [==============================] - 642s 843ms/step - loss: 0.0582 - acc: 0.9768 - val_loss: 0.1450 - val_acc: 0.9495\n",
      "Epoch 32/80\n",
      "761/760 [==============================] - 642s 844ms/step - loss: 0.0572 - acc: 0.9778 - val_loss: 0.1487 - val_acc: 0.9490\n",
      "Epoch 33/80\n",
      "761/760 [==============================] - 642s 844ms/step - loss: 0.0563 - acc: 0.9771 - val_loss: 0.1601 - val_acc: 0.9430\n",
      "Epoch 34/80\n",
      "761/760 [==============================] - 642s 843ms/step - loss: 0.0547 - acc: 0.9789 - val_loss: 0.1550 - val_acc: 0.9485\n",
      "Epoch 35/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.0530 - acc: 0.9797 - val_loss: 0.1473 - val_acc: 0.9455\n",
      "Epoch 36/80\n",
      "761/760 [==============================] - 642s 844ms/step - loss: 0.0517 - acc: 0.9795 - val_loss: 0.1624 - val_acc: 0.9405\n",
      "Epoch 37/80\n",
      "761/760 [==============================] - 642s 843ms/step - loss: 0.0488 - acc: 0.9814 - val_loss: 0.1499 - val_acc: 0.9530\n",
      "Epoch 38/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.0491 - acc: 0.9804 - val_loss: 0.1334 - val_acc: 0.9590\n",
      "Epoch 39/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.0475 - acc: 0.9810 - val_loss: 0.1468 - val_acc: 0.9565\n",
      "Epoch 40/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.0442 - acc: 0.9837 - val_loss: 0.1508 - val_acc: 0.9490\n",
      "Epoch 41/80\n",
      "761/760 [==============================] - 642s 843ms/step - loss: 0.0393 - acc: 0.9848 - val_loss: 0.1464 - val_acc: 0.9520\n",
      "Epoch 42/80\n",
      "761/760 [==============================] - 640s 842ms/step - loss: 0.0390 - acc: 0.9848 - val_loss: 0.1637 - val_acc: 0.9465\n",
      "Epoch 43/80\n",
      "761/760 [==============================] - 641s 843ms/step - loss: 0.0393 - acc: 0.9854 - val_loss: 0.1482 - val_acc: 0.9530\n",
      "Epoch 44/80\n",
      "761/760 [==============================] - 642s 843ms/step - loss: 0.0380 - acc: 0.9850 - val_loss: 0.1801 - val_acc: 0.9455\n",
      "Epoch 45/80\n",
      "761/760 [==============================] - 641s 843ms/step - loss: 0.0357 - acc: 0.9859 - val_loss: 0.1682 - val_acc: 0.9515\n",
      "Epoch 46/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.0374 - acc: 0.9854 - val_loss: 0.1739 - val_acc: 0.9500\n",
      "Epoch 47/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.0360 - acc: 0.9862 - val_loss: 0.1655 - val_acc: 0.9505\n",
      "Epoch 48/80\n",
      "761/760 [==============================] - 641s 842ms/step - loss: 0.0361 - acc: 0.9862 - val_loss: 0.1633 - val_acc: 0.9540\n",
      "Epoch 49/80\n",
      "761/760 [==============================] - 641s 842ms/step - loss: 0.0351 - acc: 0.9862 - val_loss: 0.1559 - val_acc: 0.9485\n",
      "Epoch 50/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.0340 - acc: 0.9872 - val_loss: 0.1720 - val_acc: 0.9520\n",
      "Epoch 51/80\n",
      "761/760 [==============================] - 640s 840ms/step - loss: 0.0317 - acc: 0.9878 - val_loss: 0.1585 - val_acc: 0.9555\n",
      "Epoch 53/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.0318 - acc: 0.9875 - val_loss: 0.1628 - val_acc: 0.9520\n",
      "Epoch 54/80\n",
      "761/760 [==============================] - 637s 837ms/step - loss: 0.0312 - acc: 0.9884 - val_loss: 0.1768 - val_acc: 0.9540\n",
      "Epoch 55/80\n",
      "761/760 [==============================] - 637s 837ms/step - loss: 0.0312 - acc: 0.9886 - val_loss: 0.1593 - val_acc: 0.9525\n",
      "Epoch 56/80\n",
      "761/760 [==============================] - 638s 839ms/step - loss: 0.0298 - acc: 0.9885 - val_loss: 0.1733 - val_acc: 0.9530\n",
      "Epoch 57/80\n",
      "761/760 [==============================] - 638s 839ms/step - loss: 0.0295 - acc: 0.9889 - val_loss: 0.1892 - val_acc: 0.9475\n",
      "Epoch 58/80\n",
      "761/760 [==============================] - 640s 840ms/step - loss: 0.0300 - acc: 0.9891 - val_loss: 0.1809 - val_acc: 0.9485\n",
      "Epoch 59/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.0300 - acc: 0.9893 - val_loss: 0.1799 - val_acc: 0.9515\n",
      "Epoch 60/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.0287 - acc: 0.9895 - val_loss: 0.1730 - val_acc: 0.9575\n",
      "Epoch 61/80\n",
      "761/760 [==============================] - 643s 845ms/step - loss: 0.0283 - acc: 0.9899 - val_loss: 0.1746 - val_acc: 0.9545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.0258 - acc: 0.9904 - val_loss: 0.1521 - val_acc: 0.9595\n",
      "Epoch 63/80\n",
      "761/760 [==============================] - 640s 842ms/step - loss: 0.0273 - acc: 0.9896 - val_loss: 0.1680 - val_acc: 0.9480\n",
      "Epoch 64/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.0267 - acc: 0.9904 - val_loss: 0.1962 - val_acc: 0.9525\n",
      "Epoch 65/80\n",
      "761/760 [==============================] - 639s 839ms/step - loss: 0.0266 - acc: 0.9902 - val_loss: 0.1716 - val_acc: 0.9555\n",
      "Epoch 66/80\n",
      "761/760 [==============================] - 635s 834ms/step - loss: 0.0249 - acc: 0.9907 - val_loss: 0.1730 - val_acc: 0.9560\n",
      "Epoch 67/80\n",
      "761/760 [==============================] - 640s 841ms/step - loss: 0.0248 - acc: 0.9905 - val_loss: 0.1900 - val_acc: 0.9430\n",
      "Epoch 68/80\n",
      "761/760 [==============================] - 639s 839ms/step - loss: 0.0271 - acc: 0.9900 - val_loss: 0.1669 - val_acc: 0.9560\n",
      "Epoch 69/80\n",
      "761/760 [==============================] - 643s 845ms/step - loss: 0.0260 - acc: 0.9908 - val_loss: 0.1862 - val_acc: 0.9535\n",
      "Epoch 70/80\n",
      "761/760 [==============================] - 638s 838ms/step - loss: 0.0268 - acc: 0.9905 - val_loss: 0.1665 - val_acc: 0.9540\n",
      "Epoch 71/80\n",
      "761/760 [==============================] - 639s 840ms/step - loss: 0.0255 - acc: 0.9903 - val_loss: 0.1652 - val_acc: 0.9585\n",
      "Epoch 72/80\n",
      "761/760 [==============================] - 638s 839ms/step - loss: 0.0238 - acc: 0.9908 - val_loss: 0.1661 - val_acc: 0.9570\n",
      "Epoch 73/80\n",
      "761/760 [==============================] - 638s 839ms/step - loss: 0.0244 - acc: 0.9909 - val_loss: 0.1885 - val_acc: 0.9495\n",
      "Epoch 74/80\n",
      "761/760 [==============================] - 635s 834ms/step - loss: 0.0242 - acc: 0.9906 - val_loss: 0.1784 - val_acc: 0.9490\n",
      "Epoch 75/80\n",
      "761/760 [==============================] - 627s 823ms/step - loss: 0.0237 - acc: 0.9914 - val_loss: 0.2026 - val_acc: 0.9470\n",
      "Epoch 76/80\n",
      "761/760 [==============================] - 638s 839ms/step - loss: 0.0255 - acc: 0.9901 - val_loss: 0.1855 - val_acc: 0.9520\n",
      "Epoch 77/80\n",
      "761/760 [==============================] - 636s 836ms/step - loss: 0.0249 - acc: 0.9907 - val_loss: 0.1891 - val_acc: 0.9550\n",
      "Epoch 78/80\n",
      "761/760 [==============================] - 636s 836ms/step - loss: 0.0255 - acc: 0.9902 - val_loss: 0.1717 - val_acc: 0.9565\n",
      "Epoch 79/80\n",
      "761/760 [==============================] - 638s 839ms/step - loss: 0.0235 - acc: 0.9908 - val_loss: 0.1616 - val_acc: 0.9590\n",
      "Epoch 80/80\n",
      "761/760 [==============================] - 637s 837ms/step - loss: 0.0249 - acc: 0.9908 - val_loss: 0.1734 - val_acc: 0.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f802d137a90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_samples_train/batch_size,\n",
    "        epochs=80,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=nb_samples_val/batch_size,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model and weights\n",
    "model.save('my_model2.h5')\n",
    "model.save_weights('my_weights2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "As GitHub doesn't allow to upload files of more than 100Mb, I converted the model to decrease the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shipinskaya_sofi/anaconda3/lib/python3.6/site-packages/tensorflow/lite/python/lite.py:591: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /home/shipinskaya_sofi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 100 variables.\n",
      "INFO:tensorflow:Converted 100 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46791100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting keras model to tflite model\n",
    "converter = lite.TFLiteConverter.from_keras_model_file('my_model2.h5')\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function for loading and rescaling images\n",
    "def load_image(img_path):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_tensor = image.img_to_array(img)                    \n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         \n",
    "    img_tensor /= 255.\n",
    "    \n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading converted model, setting input and output\n",
    "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing predictions\n",
    "pred = []\n",
    "for subdir, dirs, files in os.walk('full dataset/test'):\n",
    "    for file in files:\n",
    "        input_data = load_image(os.path.join(subdir, file))\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        pred.append(output_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision is: 0.9960567357\n"
     ]
    }
   ],
   "source": [
    "# calculating avarage percision\n",
    "average_precision = average_precision_score(test_generator.classes, [x[1] for x in pred])\n",
    "print('Average precision is: {0:0.10f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comment\n",
    "So, I trained here 80 epochs, the average precision is quite high (99.6%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
