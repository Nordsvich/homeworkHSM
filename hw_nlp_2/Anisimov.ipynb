{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anisimov Anton NLP HW2 (BBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short plan(aka pipeline):\n",
    "#     1)prepare the datasets\n",
    "#     2)try models such as:log-reg,randomforest,CNN\n",
    "#     3)compere results\n",
    "## Metrix: f1 weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# data prep\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# models\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD CLASSES PATH and NAMES\n",
    "path='bbc-fulltext/bbc/'\n",
    "cat=glob.glob(path+'*')\n",
    "cat=[cat[i].split('\\\\')[-1] for i in range(0,len(cat))]\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "text=[]\n",
    "labels=[]\n",
    "k=0\n",
    "for i in cat:\n",
    "    d=glob.glob('bbc-fulltext/bbc/'+i+'/*.txt')\n",
    "    for i in d:\n",
    "        try:\n",
    "    # block raising an exception\n",
    "          with open(i, 'r') as file:\n",
    "                data = file.read().replace('\\n', '')\n",
    "                text.append([data])\n",
    "                labels.append(k)\n",
    "        except:\n",
    "            pass \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD composed data to pandas\n",
    "df = pd.DataFrame(data=text,columns=['observation'])\n",
    "df['final_labels']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>observation</th>\n",
       "      <th>final_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ad sales boost Time Warner profitQuarterly pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dollar gains on Greenspan speechThe dollar has...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yukos unit buyer faces loan claimThe owners of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>High fuel prices hit BA's profitsBritish Airwa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pernod takeover talk lifts DomecqShares in UK ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        observation  final_labels\n",
       "0           0  Ad sales boost Time Warner profitQuarterly pro...             0\n",
       "1           1  Dollar gains on Greenspan speechThe dollar has...             0\n",
       "2           2  Yukos unit buyer faces loan claimThe owners of...             0\n",
       "3           3  High fuel prices hit BA's profitsBritish Airwa...             0\n",
       "4           4  Pernod takeover talk lifts DomecqShares in UK ...             0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df.to_csv('bbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>final_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profitQuarterly pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speechThe dollar has...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claimThe owners of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profitsBritish Airwa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts DomecqShares in UK ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         observation  final_labels\n",
       "0  Ad sales boost Time Warner profitQuarterly pro...             0\n",
       "1  Dollar gains on Greenspan speechThe dollar has...             0\n",
       "2  Yukos unit buyer faces loan claimThe owners of...             0\n",
       "3  High fuel prices hit BA's profitsBritish Airwa...             0\n",
       "4  Pernod takeover talk lifts DomecqShares in UK ...             0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('bbc.csv')\n",
    "df=df.drop(columns=df.columns[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    510\n",
       "1    386\n",
       "2    417\n",
       "3    511\n",
       "4    401\n",
       "Name: final_labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y=df['observation'],df.iloc[:,-1]\n",
    "#check class balance\n",
    "y.iloc[:].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Bags of words set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>000a</th>\n",
       "      <th>000bn</th>\n",
       "      <th>000four</th>\n",
       "      <th>000m</th>\n",
       "      <th>000s</th>\n",
       "      <th>000th</th>\n",
       "      <th>001</th>\n",
       "      <th>...</th>\n",
       "      <th>вј952m</th>\n",
       "      <th>вј960m</th>\n",
       "      <th>вј96bn</th>\n",
       "      <th>вј97m</th>\n",
       "      <th>вј98</th>\n",
       "      <th>вј980m</th>\n",
       "      <th>вј98m</th>\n",
       "      <th>вј99</th>\n",
       "      <th>вј9m</th>\n",
       "      <th>ј15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0001  000a  000bn  000four  000m  000s  000th  001  ...  вј952m  \\\n",
       "0   0    1     0     0      0        0     0     0      0    0  ...       0   \n",
       "1   0    0     0     0      0        0     0     0      0    0  ...       0   \n",
       "2   0    0     0     0      0        0     0     0      0    0  ...       0   \n",
       "3   0    1     0     0      0        0     0     0      0    0  ...       0   \n",
       "4   0    0     0     0      0        0     0     0      0    0  ...       0   \n",
       "\n",
       "   вј960m  вј96bn  вј97m  вј98  вј980m  вј98m  вј99  вј9m  ј15  \n",
       "0       0       0      0     0       0      0     0     0    0  \n",
       "1       0       0      0     0       0      0     0     0    0  \n",
       "2       0       0      0     0       0      0     0     0    0  \n",
       "3       0       0      0     0       0      0     0     0    0  \n",
       "4       0       0      0     0       0      0     0     0    0  \n",
       "\n",
       "[5 rows x 31623 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary\n",
    "vectorizer = CountVectorizer()\n",
    "Vec = vectorizer.fit_transform(X,y=y)\n",
    "df_bags=pd.DataFrame(data=Vec.toarray(),columns=vectorizer.get_feature_names())\n",
    "df_bags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tf-idа set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>000a</th>\n",
       "      <th>000bn</th>\n",
       "      <th>000four</th>\n",
       "      <th>000m</th>\n",
       "      <th>000s</th>\n",
       "      <th>000th</th>\n",
       "      <th>001</th>\n",
       "      <th>...</th>\n",
       "      <th>вј952m</th>\n",
       "      <th>вј960m</th>\n",
       "      <th>вј96bn</th>\n",
       "      <th>вј97m</th>\n",
       "      <th>вј98</th>\n",
       "      <th>вј980m</th>\n",
       "      <th>вј98m</th>\n",
       "      <th>вј99</th>\n",
       "      <th>вј9m</th>\n",
       "      <th>ј15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31623 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00       000  0001  000a  000bn  000four  000m  000s  000th  001  ...  \\\n",
       "0  0.0  0.020955   0.0   0.0    0.0      0.0   0.0   0.0    0.0  0.0  ...   \n",
       "1  0.0  0.000000   0.0   0.0    0.0      0.0   0.0   0.0    0.0  0.0  ...   \n",
       "2  0.0  0.000000   0.0   0.0    0.0      0.0   0.0   0.0    0.0  0.0  ...   \n",
       "3  0.0  0.018927   0.0   0.0    0.0      0.0   0.0   0.0    0.0  0.0  ...   \n",
       "4  0.0  0.000000   0.0   0.0    0.0      0.0   0.0   0.0    0.0  0.0  ...   \n",
       "\n",
       "   вј952m  вј960m  вј96bn  вј97m  вј98  вј980m  вј98m  вј99  вј9m  ј15  \n",
       "0     0.0     0.0     0.0    0.0   0.0     0.0    0.0   0.0   0.0  0.0  \n",
       "1     0.0     0.0     0.0    0.0   0.0     0.0    0.0   0.0   0.0  0.0  \n",
       "2     0.0     0.0     0.0    0.0   0.0     0.0    0.0   0.0   0.0  0.0  \n",
       "3     0.0     0.0     0.0    0.0   0.0     0.0    0.0   0.0   0.0  0.0  \n",
       "4     0.0     0.0     0.0    0.0   0.0     0.0    0.0   0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 31623 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "Vec=vectorizer.fit_transform(X,y)\n",
    "col=vectorizer.get_feature_names()\n",
    "df_tf=pd.DataFrame(Vec.todense(),columns=col)\n",
    "df_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental cleaning up:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheking tresh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "don           444\n",
       "service       452\n",
       "during        456\n",
       "chief         457\n",
       "growth        458\n",
       "london        459\n",
       "own           460\n",
       "me            465\n",
       "day           466\n",
       "come          466\n",
       "months        466\n",
       "brown         470\n",
       "plans         471\n",
       "put           472\n",
       "already       473\n",
       "half          473\n",
       "old           478\n",
       "six           481\n",
       "sales         489\n",
       "even          496\n",
       "group         496\n",
       "four          496\n",
       "expected      505\n",
       "where         513\n",
       "news          513\n",
       "end           514\n",
       "both          514\n",
       "these         514\n",
       "however       514\n",
       "tv            517\n",
       "            ...  \n",
       "this         2844\n",
       "we           3004\n",
       "mr           3005\n",
       "his          3026\n",
       "they         3083\n",
       "not          3484\n",
       "from         3535\n",
       "are          4401\n",
       "but          4419\n",
       "will         4472\n",
       "by           4511\n",
       "at           4634\n",
       "have         4771\n",
       "has          4956\n",
       "as           4974\n",
       "with         5352\n",
       "be           5805\n",
       "he           5939\n",
       "was          6023\n",
       "said         7255\n",
       "on           7619\n",
       "it           7887\n",
       "that         8256\n",
       "is           8554\n",
       "for          8941\n",
       "in          17715\n",
       "and         18607\n",
       "of          20006\n",
       "to          25113\n",
       "the         52322\n",
       "Length: 200, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select tresh by freq\n",
    "a=df_bags.sum().sort_values()\n",
    "a[-200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " About 200 last freq words are the useless(general articles and etc) and there are lot of words which use ones about 25000. However, I'm going to drop them and try to \"experimental learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"tresh\"\n",
    "a=list(a[:25000].index) + list(a[-400:].index)\n",
    "df_cl=df_bags.drop(columns=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b_train, X_b_test, y_b_train, y_b_test = train_test_split(df_bags.iloc[:,:], y, test_size=0.33, random_state=20)\n",
    "X_tf_train, X_tf_test, y_tf_train, y_tf_test = train_test_split(df_tf.iloc[:,:], y, test_size=0.33, random_state=20)\n",
    "X_cl_train, X_cl_test, y_cl_train, y_cl_test = train_test_split(df_cl.iloc[:,:], y, test_size=0.33, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mat=[[X_b_train, X_b_test, y_b_train, y_b_test],\n",
    "        [X_tf_train, X_tf_test, y_tf_train, y_tf_test],\n",
    "        [X_cl_train, X_cl_test, y_cl_train, y_cl_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score matrix\n",
    "final_columns='bags','tfidf,cl_bags'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to save model\n",
    "def save_model(Model,name):\n",
    "    import pickle\n",
    "    a=0\n",
    "    for i in Model:\n",
    "        name=name+str(a)+'.sav'\n",
    "        pickle.dump(i, open(name, 'wb'))\n",
    "        a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-reg.CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.963600540940382 test: 0.9632187302100251\n",
      "train: 0.9696159145360694 test: 0.9619800018738477\n",
      "train: 0.9662463199475176 test: 0.9646021386705141\n"
     ]
    }
   ],
   "source": [
    "Models_log=[]\n",
    "score_log=[]\n",
    "for i in range(0,3):\n",
    "    Model1 = LogisticRegression(random_state=0, solver='newton-cg',\n",
    "                             multi_class='multinomial').fit(set_mat[i][0], set_mat[i][2])\n",
    "    train_scores = cross_val_score(Model1, set_mat[i][0], set_mat[i][2], cv=5,scoring='f1_weighted').mean()\n",
    "    test_scores=metrics.f1_score(y_true=set_mat[i][3],y_pred=Model1.predict(set_mat[i][1]),average='weighted')\n",
    "    print ('train:',train_scores,'test:',test_scores)\n",
    "    score_log.append(test_scores)\n",
    "    Models_log.append(Model1)\n",
    "scores.append(score_log)\n",
    "# save models\n",
    "save_model(Models_log,'Models/Log_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log res shows simular scores on all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid param\n",
    "tuned_parameters = [{ 'n_estimators': [i for i in range (100,300,20)],\n",
    "                     'max_depth': [70]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 70, 'n_estimators': 260}\n",
      "train: 0.9580030216785804 test: 0.9471361343205387\n",
      "{'max_depth': 70, 'n_estimators': 220}\n",
      "train: 0.9574553717237544 test: 0.9442651972509771\n",
      "{'max_depth': 70, 'n_estimators': 280}\n",
      "train: 0.9515462171353745 test: 0.9373673135135523\n"
     ]
    }
   ],
   "source": [
    "Models_for=[]\n",
    "score_for=[]\n",
    "for i in range(0,3):\n",
    "    Model2 = GridSearchCV(RandomForestClassifier(),\n",
    "                      tuned_parameters, cv=5, scoring='f1_weighted',n_jobs=6)\n",
    "    Model2.fit(set_mat[i][0], set_mat[i][2])\n",
    "    train_scores=Model2.best_score_\n",
    "    print(Model2.best_params_)\n",
    "    Model2=Model2.best_estimator_\n",
    "    test_scores=metrics.f1_score(y_true=set_mat[i][3],y_pred=Model2.predict(set_mat[i][1]),average='weighted')\n",
    "    print ('train:',train_scores,'test:',test_scores)\n",
    "    score_for.append(test_scores)\n",
    "    Models_for.append(Model2)\n",
    "scores.append(score_for)\n",
    "# save models\n",
    "save_model(Models_for,'Models/RF_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, all results are near to each other, ifidf needs less trees that bags of words. Anyway short clean data set needs more trees, but shows the same perfomance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xg-boost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['multi:softmax'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [50],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [i for i in range (100,300,25)],\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models_xg=[]\n",
    "# score_xg=[]\n",
    "# for i in range(0,3):\n",
    "#     Model2 = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "#                    cv=5,scoring='f1_weighted')\n",
    "#     Model2.fit(set_mat[i][0], set_mat[i][2])\n",
    "#     train_scores=Model2.best_score_\n",
    "#     print(Model2.best_params_)\n",
    "#     Model2=Model2.best_estimator_\n",
    "#     test_scores=metrics.f1_score(y_true=set_mat[i][3],y_pred=Model2.predict(set_mat[i][1]),average='weighted')\n",
    "#     print ('train:',train_scores,'test:',test_scores)\n",
    "#     score_xg.append(test_scores)\n",
    "#     Models_xg.append(Model2)\n",
    "# scores.append(score_xg)\n",
    "# # save models\n",
    "# save_model(Models_xg,'XG_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Dense,Activation,Dropout,BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import adam\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelFNN(X_train,N,drop):    \n",
    "    inputs = Input(shape=(X_train.shape[1],))\n",
    "    x=Dense(N, activation='relu',kernel_regularizer=regularizers.l2(0.0009))(inputs)\n",
    "    drop=Dropout(drop)(x)\n",
    "    x=Dense(N, activation='relu',kernel_regularizer=regularizers.l2(0.0008))(drop)\n",
    "    output_layer = Dense(5, activation = 'softmax')(x)\n",
    "    model1 = Model(inputs=inputs, outputs=output_layer,)\n",
    "    ADAM=adam(lr=0.0001)\n",
    "    model1.compile(optimizer=ADAM,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', f1])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=modelFNN(X_train,50,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1341 samples, validate on 149 samples\n",
      "Epoch 1/1\n",
      "1341/1341 [==============================] - 1s 865us/step - loss: 0.0695 - acc: 0.9948 - f1: 0.9661 - val_loss: 0.1525 - val_acc: 0.9732 - val_f1: 0.9645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f032b2e1710>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=16,epochs=1,validation_data=(X_val,y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "   --  0.1\n",
      "   --  0.2\n",
      "   --  0.3\n",
      "   --  0.4\n",
      "   --  0.5\n",
      "   --  0.6\n",
      "   --  0.7\n",
      "40\n",
      "   --  0.1\n",
      "   --  0.2\n",
      "   --  0.3\n",
      "   --  0.4\n",
      "   --  0.5\n",
      "   --  0.6\n",
      "   --  0.7\n",
      "70\n",
      "   --  0.1\n",
      "   --  0.2\n",
      "   --  0.3\n",
      "   --  0.4\n",
      "   --  0.5\n",
      "   --  0.6\n",
      "   --  0.7\n",
      "100\n",
      "   --  0.1\n",
      "   --  0.2\n",
      "   --  0.3\n",
      "   --  0.4\n",
      "   --  0.5\n",
      "   --  0.6\n",
      "   --  0.7\n",
      "130\n",
      "   --  0.1\n",
      "   --  0.2\n",
      "   --  0.3\n",
      "   --  0.4\n",
      "   --  0.5\n",
      "   --  0.6\n",
      "   --  0.7\n",
      "160\n",
      "   --  0.1\n",
      "   --  0.2\n",
      "   --  0.3\n",
      "   --  0.4\n",
      "   --  0.5\n",
      "   --  0.6\n",
      "   --  0.7\n",
      "190\n",
      "   --  0.1\n",
      "   --  0.2\n",
      "   --  0.3\n",
      "   --  0.4\n",
      "   --  0.5\n",
      "   --  0.6\n",
      "   --  0.7\n"
     ]
    }
   ],
   "source": [
    "# find optimal parametrs\n",
    "res=[]\n",
    "N=[i for i in range(10,200,30)]\n",
    "drop=np.linspace(0.1,0.7,7)\n",
    "for i in N:\n",
    "    print (i)\n",
    "    line=[]\n",
    "    for j in drop:\n",
    "        print ('   -- ',j)\n",
    "        model=modelFNN(X_train,i,j)\n",
    "        model.fit(X_train,y_train,batch_size=16,epochs=25,validation_data=(X_val,y_val),verbose=0)\n",
    "        preds=model.predict(X_test).argmax(1)\n",
    "        line.append(metrics.f1_score(y_true=y_test.argmax(1),y_pred=preds,average='weighted'))\n",
    "    res.append(line)\n",
    "Report=pd.DataFrame(data=res)\n",
    "Report.columns=drop;Report.index=N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report.to_csv('fnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load report \n",
    "report=pd.read_csv('fnn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.961995</td>\n",
       "      <td>0.941710</td>\n",
       "      <td>0.945479</td>\n",
       "      <td>0.950900</td>\n",
       "      <td>0.957926</td>\n",
       "      <td>0.966020</td>\n",
       "      <td>0.968778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.968721</td>\n",
       "      <td>0.960733</td>\n",
       "      <td>0.961963</td>\n",
       "      <td>0.968735</td>\n",
       "      <td>0.966069</td>\n",
       "      <td>0.956437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.966071</td>\n",
       "      <td>0.970081</td>\n",
       "      <td>0.967338</td>\n",
       "      <td>0.967355</td>\n",
       "      <td>0.963309</td>\n",
       "      <td>0.966027</td>\n",
       "      <td>0.970097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.965979</td>\n",
       "      <td>0.964637</td>\n",
       "      <td>0.971435</td>\n",
       "      <td>0.970135</td>\n",
       "      <td>0.971468</td>\n",
       "      <td>0.966052</td>\n",
       "      <td>0.964603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>0.965963</td>\n",
       "      <td>0.967396</td>\n",
       "      <td>0.966122</td>\n",
       "      <td>0.970081</td>\n",
       "      <td>0.970058</td>\n",
       "      <td>0.966042</td>\n",
       "      <td>0.967430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>160</td>\n",
       "      <td>0.963280</td>\n",
       "      <td>0.959275</td>\n",
       "      <td>0.970067</td>\n",
       "      <td>0.972780</td>\n",
       "      <td>0.971419</td>\n",
       "      <td>0.961958</td>\n",
       "      <td>0.968707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>190</td>\n",
       "      <td>0.965982</td>\n",
       "      <td>0.961990</td>\n",
       "      <td>0.965978</td>\n",
       "      <td>0.954990</td>\n",
       "      <td>0.964625</td>\n",
       "      <td>0.968687</td>\n",
       "      <td>0.968785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       0.1       0.2       0.3       0.4       0.5       0.6  \\\n",
       "0          10  0.961995  0.941710  0.945479  0.950900  0.957926  0.966020   \n",
       "1          40  0.970085  0.968721  0.960733  0.961963  0.968735  0.966069   \n",
       "2          70  0.966071  0.970081  0.967338  0.967355  0.963309  0.966027   \n",
       "3         100  0.965979  0.964637  0.971435  0.970135  0.971468  0.966052   \n",
       "4         130  0.965963  0.967396  0.966122  0.970081  0.970058  0.966042   \n",
       "5         160  0.963280  0.959275  0.970067  0.972780  0.971419  0.961958   \n",
       "6         190  0.965982  0.961990  0.965978  0.954990  0.964625  0.968687   \n",
       "\n",
       "        0.7  \n",
       "0  0.968778  \n",
       "1  0.956437  \n",
       "2  0.970097  \n",
       "3  0.964603  \n",
       "4  0.967430  \n",
       "5  0.968707  \n",
       "6  0.968785  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score parametrs :\n",
    "test score: 0.972780\n",
    "drop:0.4 \n",
    "new:160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasets perfomans comperasion cnn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat=np_utils.to_categorical(y,5)\n",
    "X_b_train, X_b_test, y_b_train, y_b_test = train_test_split(df_bags.iloc[:,:], y_cat, test_size=0.33, random_state=20)\n",
    "X_tf_train, X_tf_test, y_tf_train, y_tf_test = train_test_split(df_tf.iloc[:,:], y_cat, test_size=0.33, random_state=20)\n",
    "X_cl_train, X_cl_test, y_cl_train, y_cl_test = train_test_split(df_cl.iloc[:,:], y_cat, test_size=0.33, random_state=20)\n",
    "set_mat=[[X_b_train, X_b_test, y_b_train, y_b_test],\n",
    "        [X_tf_train, X_tf_test, y_tf_train, y_tf_test],\n",
    "        [X_cl_train, X_cl_test, y_cl_train, y_cl_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1.0 test: 0.9728139720512199\n",
      "train: 1.0 test: 0.9727913064717708\n",
      "train: 1.0 test: 0.9645847196452797\n"
     ]
    }
   ],
   "source": [
    "Models_cnn=[]\n",
    "score_cnn=[]\n",
    "for i in range(0,3):\n",
    "    model=modelFNN(set_mat[i][0],160,0.4)\n",
    "    model.fit(set_mat[i][0], set_mat[i][2],batch_size=16,epochs=25,verbose=0)\n",
    "    train_scores = metrics.f1_score(y_true=set_mat[i][2].argmax(1),y_pred=model.predict(set_mat[i][0]).argmax(1),average='weighted')\n",
    "    test_scores=metrics.f1_score(y_true=set_mat[i][3].argmax(1),y_pred=model.predict(set_mat[i][1]).argmax(1),average='weighted')\n",
    "    print ('train:',train_scores,'test:',test_scores)\n",
    "    score_cnn.append(test_scores)\n",
    "    Models_cnn.append(model)\n",
    "    # save models\n",
    "    model.save('Models/cnn'+str(i)+'.h5')\n",
    "    model.save_weights('Models/cnn_w'+str(i)+'.h5')\n",
    "scores.append(score_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.DataFrame(data=score,columns=['bag_words','ifidf','Clean_bag'],\n",
    "                   index=['Log-reg','Random forest','CNN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bag_words</th>\n",
       "      <th>ifidf</th>\n",
       "      <th>Clean_bag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log-reg</th>\n",
       "      <td>0.963219</td>\n",
       "      <td>0.961980</td>\n",
       "      <td>0.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.947136</td>\n",
       "      <td>0.944265</td>\n",
       "      <td>0.937367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.972814</td>\n",
       "      <td>0.972791</td>\n",
       "      <td>0.964585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bag_words     ifidf  Clean_bag\n",
       "Log-reg         0.963219  0.961980   0.964602\n",
       "Random forest   0.947136  0.944265   0.937367\n",
       "CNN             0.972814  0.972791   0.964585"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is cnn (through the results), shown f1=0.97 on the main bag_words, but if you play with the parameter, you can get the same results for Clean_bag. Summarize that clean_bag is good, of course, it is easier basic and can be used to get close or even the same results as others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
