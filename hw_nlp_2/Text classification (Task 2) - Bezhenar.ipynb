{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework №2: Text classification (task 2)\n",
    "*Bezhenaer OLga*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task: \n",
    "Classify news to one of 5 categories based on text\n",
    "\n",
    "1. Choose and argue your measure of a test's accuracy.\n",
    "2. Build data processing and classification pipeline\n",
    "3. Tune  your model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data from folders and creation of the dataset\n",
    "data_folder = \"C:/Users/Коля/Desktop/NLP/bbc\"\n",
    "folders = [\"business\",\"entertainment\",\"politics\",\"sport\",\"tech\"]\n",
    "\n",
    "os.chdir(data_folder)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in folders:\n",
    "    files = os.listdir(i)\n",
    "    for text_file in files:\n",
    "        file_path = i + \"/\" +text_file\n",
    "        #print (\"reading file:\", file_path)\n",
    "        with open(file_path) as f:\n",
    "            data = f.readlines()\n",
    "        data = ' '.join(data)\n",
    "        x.append(data)\n",
    "        y.append(i)\n",
    " \n",
    "data = {'news': x, 'type': y}       \n",
    "df = pd.DataFrame(data)\n",
    "#print ('writing csv flie ...')\n",
    "df.to_csv('../dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n \\n Quarter...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n \\n The doll...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n \\n The own...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n \\n British...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n \\n Shares ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Japan narrowly escapes recession\\n \\n Japan's ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jobs growth still slow in the US\\n \\n The US c...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>India calls for fair trade rules\\n \\n India, w...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ethiopia's crop production up 24%\\n \\n Ethiopi...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Court rejects $280bn tobacco case\\n \\n A US go...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news      type\n",
       "0  Ad sales boost Time Warner profit\\n \\n Quarter...  business\n",
       "1  Dollar gains on Greenspan speech\\n \\n The doll...  business\n",
       "2  Yukos unit buyer faces loan claim\\n \\n The own...  business\n",
       "3  High fuel prices hit BA's profits\\n \\n British...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n \\n Shares ...  business\n",
       "5  Japan narrowly escapes recession\\n \\n Japan's ...  business\n",
       "6  Jobs growth still slow in the US\\n \\n The US c...  business\n",
       "7  India calls for fair trade rules\\n \\n India, w...  business\n",
       "8  Ethiopia's crop production up 24%\\n \\n Ethiopi...  business\n",
       "9  Court rejects $280bn tobacco case\\n \\n A US go...  business"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts() #we can say that the problem of sample inbalance is not presented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            0.229663\n",
       "business         0.229213\n",
       "politics         0.187416\n",
       "tech             0.180225\n",
       "entertainment    0.173483\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining a numeric representation of \"type\" colomn \n",
    "df['type_id'] = df['type'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb0cca116a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data visalization \n",
    "df.groupby('type').type_id.count().plot.bar(ylim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_to_id = {'business':0, 'tech':1, 'politics':2, 'sport':3, 'entertainment':4}\n",
    "id_to_type = {0: 'business', 1: 'tech', 2: 'politics', 3: 'sport', 4: 'entertainment'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>type</th>\n",
       "      <th>type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n \\n Quarter...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n \\n The doll...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n \\n The own...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n \\n British...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n \\n Shares ...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news      type  type_id\n",
       "0  Ad sales boost Time Warner profit\\n \\n Quarter...  business        0\n",
       "1  Dollar gains on Greenspan speech\\n \\n The doll...  business        0\n",
       "2  Yukos unit buyer faces loan claim\\n \\n The own...  business        0\n",
       "3  High fuel prices hit BA's profits\\n \\n British...  business        0\n",
       "4  Pernod takeover talk lifts Domecq\\n \\n Shares ...  business        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 14454)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features from text\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(df.news).toarray()\n",
    "labels = df.type_id\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business':\n",
      "  . Most correlated unigrams:\n",
      ". oil\n",
      ". growth\n",
      ". shares\n",
      "  . Most correlated bigrams:\n",
      ". analysts said\n",
      ". economic growth\n",
      ". stock market\n",
      "# 'entertainment':\n",
      "  . Most correlated unigrams:\n",
      ". technology\n",
      ". software\n",
      ". users\n",
      "  . Most correlated bigrams:\n",
      ". anti virus\n",
      ". mobile phones\n",
      ". mobile phone\n",
      "# 'politics':\n",
      "  . Most correlated unigrams:\n",
      ". blair\n",
      ". election\n",
      ". labour\n",
      "  . Most correlated bigrams:\n",
      ". prime minister\n",
      ". tony blair\n",
      ". mr blair\n",
      "# 'sport':\n",
      "  . Most correlated unigrams:\n",
      ". coach\n",
      ". match\n",
      ". cup\n",
      "  . Most correlated bigrams:\n",
      ". grand slam\n",
      ". australian open\n",
      ". champions league\n",
      "# 'tech':\n",
      "  . Most correlated unigrams:\n",
      ". singer\n",
      ". actor\n",
      ". film\n",
      "  . Most correlated bigrams:\n",
      ". los angeles\n",
      ". film festival\n",
      ". box office\n"
     ]
    }
   ],
   "source": [
    "#  finding corelation between features (importantce of words) and labels(news category)\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "N = 3\n",
    "for news, type_id in sorted(type_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == type_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  print(\"# '{}':\".format(news))\n",
    "  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3,random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part various models are compared in order to choose the optimal one. \n",
    "As the measure of test's accuracy f1, as it comprises both precision and recall metrics and does not suffer as \"accuracy\" metric from sample imbalance.\n",
    "\n",
    "F1 'weighted'\"calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall (c) sklearn documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95       140\n",
      "          1       1.00      0.92      0.96       124\n",
      "          2       0.96      0.97      0.97       136\n",
      "          3       0.99      0.99      0.99       159\n",
      "          4       0.93      0.95      0.94       109\n",
      "\n",
      "avg / total       0.96      0.96      0.96       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (Multinomial) Naive Bayes\n",
    "\n",
    "NB_model= MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "NB_pred = NB_model.predict(X_test)\n",
    "print(classification_report(y_test, NB_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.95      0.96       140\n",
      "          1       1.00      0.97      0.98       124\n",
      "          2       0.97      0.97      0.97       136\n",
      "          3       0.98      1.00      0.99       159\n",
      "          4       0.93      0.95      0.94       109\n",
      "\n",
      "avg / total       0.97      0.97      0.97       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "\n",
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(X_train, y_train)\n",
    "LR_pred = LR_model.predict(X_test)\n",
    "print(classification_report(y_test, LR_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95       140\n",
      "          1       0.99      0.91      0.95       124\n",
      "          2       0.97      0.95      0.96       136\n",
      "          3       0.94      1.00      0.97       159\n",
      "          4       0.98      0.92      0.95       109\n",
      "\n",
      "avg / total       0.96      0.96      0.95       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest \n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators=50)\n",
    "RF_model.fit(X_train, y_train)\n",
    "RF_pred = RF_model.predict(X_test)\n",
    "print(classification_report(y_test, RF_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.96       140\n",
      "          1       1.00      0.98      0.99       124\n",
      "          2       0.96      0.99      0.97       136\n",
      "          3       0.99      0.99      0.99       159\n",
      "          4       0.98      0.98      0.98       109\n",
      "\n",
      "avg / total       0.98      0.98      0.98       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear Support Vector Machine\n",
    "\n",
    "SVC_model = LinearSVC()\n",
    "SVC_model.fit(X_train, y_train)\n",
    "SVC_pred = SVC_model.predict(X_test)\n",
    "print(classification_report(y_test, SVC_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "Models performance (according to average f1 score):\n",
    "- Naive Bayes f1 = 0.96\n",
    "- Logistic Regression f1 = 0.97\n",
    "- Random Forest f1 = 0.95\n",
    "- SVC f1 = 0.98\n",
    "\n",
    "So for tunning the models with the highest performance are chosen. (LR_model and SVC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMETERS: {'C': 100, 'penalty': 'l2'}\n",
      "BEST SCORE: 0.9820191557854906\n"
     ]
    }
   ],
   "source": [
    "#creation of the parameter grid for LR\n",
    "param_grid_LR = {'penalty': ['l1', 'l2'],'C': [0.0001, 0.001, 0.01, 1, 100]}\n",
    "\n",
    "# looking for best model\n",
    "tunning_LR = grid_search.GridSearchCV(LR_model, param_grid_LR, scoring = 'f1_weighted', cv = 10)\n",
    "tunning_LR.fit(X_train, y_train)\n",
    "\n",
    "# checking what is the best model\n",
    "tunning_LR.best_estimator_\n",
    "print(\"BEST PARAMETERS:\" ,tunning_LR.best_params_)\n",
    "print(\"BEST SCORE:\",tunning_LR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMETERS: {'C': 1, 'multi_class': 'crammer_singer'}\n",
      "BEST SCORE: 0.9839426802467622\n"
     ]
    }
   ],
   "source": [
    "#creation of the parameter grid for SVC \n",
    "param_grid_SVC = { 'multi_class':['ovr','crammer_singer'],'C': [0.0001, 0.001, 0.01, 1, 100]}\n",
    "\n",
    "# looking for best model\n",
    "tunning_SVC = grid_search.GridSearchCV(SVC_model, param_grid_SVC, scoring = 'f1_weighted', cv = 10)\n",
    "tunning_SVC.fit(X_train, y_train)\n",
    "\n",
    "# checking what is the best model\n",
    "tunning_SVC.best_estimator_\n",
    "print(\"BEST PARAMETERS:\" ,tunning_SVC.best_params_)\n",
    "print(\"BEST SCORE:\",tunning_SVC.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning results:\n",
    "The best performance ('f1_weighted'=0.0.984) Linear Support Vector Machine model shows with 'C'=1 and 'multi_class'- 'crammer_singer'. \n",
    "Also the high performance ('f1_weighted'=0.982) Logistic Regression model shows with 'C'=100 and penalty = 'l2'. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*P.S.:in that case I do not implement Feature Selection as due to such 'good' dataset models shows quite high performance.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
