{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlip-hw4-colab.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or7j9BavH8a7",
        "colab_type": "text"
      },
      "source": [
        "# HW4: Movie Review Sentiment Analysis\n",
        "*Boris Evstratov*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPlytUEzIGon",
        "colab_type": "text"
      },
      "source": [
        "## Task:\n",
        "1. Choose and argue your measure of a test's accuracy;\n",
        "2. Build data processing and classification pipeline; Please compare word-embeddings vs classical methods;\n",
        "3. Tune your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvt7uPJrR95J",
        "colab_type": "text"
      },
      "source": [
        "### 0. Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYwAir3WIQwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "851868dd-9d31-4435-f877-00a57d21d341"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import zeros\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional,CuDNNLSTM,CuDNNGRU,Dense,Dropout,Embedding,LocallyConnected1D\n",
        "from keras.layers import Conv1D,GlobalAveragePooling1D,MaxPooling1D,GlobalMaxPooling1D,Flatten\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical,np_utils\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics as sklm\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer,PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgqSQsTqZijb",
        "colab_type": "text"
      },
      "source": [
        "### 1. Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAhjuUBBSBE0",
        "colab_type": "text"
      },
      "source": [
        "#### 1.1 Data import and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj7BJo0ALCso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert CSVs to Panda's dataframes\n",
        "features_train = ['pid','sid','p','s']\n",
        "features_test = ['pid','sid','p']\n",
        "train = pd.read_csv('train.tsv', names=features_train, sep=\"\\t\", header=0)\n",
        "test = pd.read_csv('test.tsv', names=features_test, sep=\"\\t\", header=0)\n",
        "sub = pd.read_csv('sampleSubmission.csv', sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22Vm5tADSOtl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "01d0d83c-e14a-432e-b00a-3beefde0af86"
      },
      "source": [
        "train.tail()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80884</th>\n",
              "      <td>80885</td>\n",
              "      <td>4169</td>\n",
              "      <td>less pimps</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80885</th>\n",
              "      <td>80886</td>\n",
              "      <td>4169</td>\n",
              "      <td>pimps</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80886</th>\n",
              "      <td>80887</td>\n",
              "      <td>4169</td>\n",
              "      <td>ho 's</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80887</th>\n",
              "      <td>80888</td>\n",
              "      <td>4169</td>\n",
              "      <td>ho</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80888</th>\n",
              "      <td>80889</td>\n",
              "      <td>4170</td>\n",
              "      <td>The</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PhraseId  SentenceId      Phrase  Sentiment\n",
              "80884     80885        4169  less pimps        2.0\n",
              "80885     80886        4169       pimps        2.0\n",
              "80886     80887        4169       ho 's        2.0\n",
              "80887     80888        4169          ho        2.0\n",
              "80888     80889        4170         The        NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuMhT4tKSZgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "abffbba3-1fa7-4271-aaff-a24b14407b91"
      },
      "source": [
        "print(train.s.value_counts())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2    79582\n",
            "3    32927\n",
            "1    27273\n",
            "4     9206\n",
            "0     7072\n",
            "Name: s, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryxtNfh-SlF8",
        "colab_type": "text"
      },
      "source": [
        "Values correspond to the following sentimentals:\n",
        "```\n",
        "0 - negative\n",
        "1 - somewhat negative\n",
        "2 - neutral\n",
        "3 - somewhat positive\n",
        "4 - positive\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw2QxsNIYh5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "5824c00a-19fe-4f9a-c72e-436932d58b45"
      },
      "source": [
        "# Stemming and Lower-casing\n",
        "X = train.p\n",
        "Y = train.s\n",
        "\n",
        "ps = PorterStemmer()\n",
        "l2 = []\n",
        "review = []\n",
        "s2 = ''\n",
        "for row in X:\n",
        "    for words in nltk.word_tokenize(row):\n",
        "            l2.append(words.lower())\n",
        "            l2.append(' ')\n",
        "    s2 = ''.join(l2)\n",
        "    review.append(s2)\n",
        "    s2 = ''\n",
        "    l2 = []\n",
        "X = review\n",
        "print(X[:1])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['a series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story . ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1PZsnkiZG16",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2 Train, Test, Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOzvwVqKZLVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bc680473-c4b7-47e5-e3c1-4ea15fa06418"
      },
      "source": [
        "X_train, X_inter, Y_train, Y_inter = train_test_split(X, Y,test_size=0.3,random_state=1)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_inter, Y_inter,test_size=0.5,random_state=1)\n",
        "print('X_train:',len(X_train))\n",
        "print('X_val:',len(X_val))\n",
        "print('X_test:',len(X_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: 109242\n",
            "X_val: 23409\n",
            "X_test: 23409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laG4YCg1sMtv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38e3b6f0-fa6c-49d1-c0d3-660fd8d39ea8"
      },
      "source": [
        "# Getting unique words\n",
        "all_words = ' '.join(X_train)\n",
        "all_words = word_tokenize(all_words)\n",
        "dist = FreqDist(all_words)\n",
        "num_unique_word = len(dist)\n",
        "num_unique_word"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16506"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1uySBnasuTA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40f1aaac-9529-4aa1-96f7-f20f8ea22ffb"
      },
      "source": [
        "# Max length of a review\n",
        "r_len = []\n",
        "for text in X_train:\n",
        "    word = word_tokenize(text)\n",
        "    l = len(word)\n",
        "    r_len.append(l)\n",
        "    \n",
        "max_review_len = np.max(r_len)\n",
        "max_review_len"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b4_vcjwsKUO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gSg-lynjO6i",
        "colab_type": "text"
      },
      "source": [
        "### 2. Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syS9-566Zqwx",
        "colab_type": "text"
      },
      "source": [
        "#### 2.1 Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U93HbI5qZuUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting training text on tokenizer for indexing\n",
        "max_sentence=len(max(X,key=len))\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BqVELw_WKi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0d3ea3e3-c7a5-4cca-f4c7-2b20a6e479ec"
      },
      "source": [
        "# Load up embeddings library\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "embeddings_index = {}\n",
        "for line in f:\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.array(values[1:],dtype = 'float32')\n",
        "    embeddings_index[word]= coefs\n",
        "f.close()\n",
        "print('Loaded',len(embeddings_index),'word vectors.')\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400001 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEelvRoGhkvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating embedded matrix\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRWKZfcHhzcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "dac12709-3176-4770-b651-a6b3ffd98f25"
      },
      "source": [
        "# Padding and conversion of the text into the sequencies\n",
        "max_sentence=len(max(X,key=len))\n",
        "\n",
        "encoded_docs = tokenizer.texts_to_sequences(X_train)\n",
        "train_x = pad_sequences(encoded_docs, maxlen=max_sentence, padding='post')\n",
        "print(train_x[0])    \n",
        "\n",
        "encoded_docs=0\n",
        "encoded_docs = tokenizer.texts_to_sequences(X_val)\n",
        "val_x = pad_sequences(encoded_docs, maxlen=max_sentence, padding='post')\n",
        "print(val_x[1])\n",
        "\n",
        "encoded_docs=0\n",
        "encoded_docs = tokenizer.texts_to_sequences(X_test)\n",
        "test_x = pad_sequences(encoded_docs, maxlen=max_sentence, padding='post')\n",
        "print(test_x[1])\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y_train)\n",
        "encoded_Y_train = encoder.transform(Y_train)\n",
        "dummy_y_train = np_utils.to_categorical(encoded_Y_train)\n",
        "print(dummy_y_train[:3])\n",
        "\n",
        "encoded_Y_val = encoder.transform(Y_val)\n",
        "\n",
        "# One-hot encoding\n",
        "dummy_y_val = np_utils.to_categorical(encoded_Y_val)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5751    4 2084   78 7002   10    3    1  364  996    9  101 1752   91\n",
            "    7  177 4902   49   31  199 2801   43    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "[285   2  46 440   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "[    1    15     8  1127 13368     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[[0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TxqqxlBjeAp",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2 CNN creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkGVoG36jdv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "e6056173-175c-4568-9165-fe90dfa7e659"
      },
      "source": [
        "# Building a multilayered Sequential model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=max_sentence, trainable=True, weights=[embedding_matrix] ))\n",
        "model.add(LocallyConnected1D(128, 2,strides=1,padding='valid', activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(256, activation='relu'))          \n",
        "model.add(Dense(5, activation='softmax'))\n",
        "print(model.summary())\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 284, 100)          1526100   \n",
            "_________________________________________________________________\n",
            "locally_connected1d_3 (Local (None, 283, 128)          7281024   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 8,841,433\n",
            "Trainable params: 8,841,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip0Ed9VYkRbs",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3 Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn6JTLNCkVEr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "b2e5013c-1ecc-4b85-a81b-60c75a210116"
      },
      "source": [
        "model.fit(train_x, dummy_y_train,  validation_data=(val_x, dummy_y_val), epochs=4,batch_size=128,verbose=1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 109242 samples, validate on 23409 samples\n",
            "Epoch 1/4\n",
            "109242/109242 [==============================] - 53s 489us/step - loss: 0.9654 - acc: 0.5990 - val_loss: 0.8815 - val_acc: 0.6300\n",
            "Epoch 2/4\n",
            "109242/109242 [==============================] - 51s 465us/step - loss: 0.7895 - acc: 0.6685 - val_loss: 0.8537 - val_acc: 0.6427\n",
            "Epoch 3/4\n",
            "109242/109242 [==============================] - 51s 464us/step - loss: 0.6792 - acc: 0.7162 - val_loss: 0.8579 - val_acc: 0.6533\n",
            "Epoch 4/4\n",
            "109242/109242 [==============================] - 51s 469us/step - loss: 0.5765 - acc: 0.7628 - val_loss: 0.9197 - val_acc: 0.6447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3e2f5b0550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2nYrkU2kc_d",
        "colab_type": "text"
      },
      "source": [
        "#### 2.4 Model evaluation and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "org1zVtcjcwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e1d89650-375d-47bf-c222-7059508d582a"
      },
      "source": [
        "# Calculate main metrics\n",
        "predictions = model.predict(test_x)\n",
        "pred=[]\n",
        "for idx,val in enumerate(predictions):\n",
        "    pred.append(np.argmax(val))\n",
        "\n",
        "print('Overall model Accuracy:  %0.2f' % sklm.accuracy_score(Y_test, pred))\n",
        "print()\n",
        "\n",
        "metrics = sklm.precision_recall_fscore_support(Y_test, pred)\n",
        "cols_name = ('0','1','2','3','4')\n",
        "rows_name = ('Precision','Recall','F1-score','Support')\n",
        "print(pd.DataFrame(metrics,rows_name,cols_name))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall model Accuracy:  0.64\n",
            "\n",
            "                     0            1             2            3            4\n",
            "Precision     0.457317     0.522884      0.744098     0.540774     0.537538\n",
            "Recall        0.287632     0.510449      0.772712     0.577564     0.409924\n",
            "F1-score      0.353149     0.516592      0.758135     0.558564     0.465136\n",
            "Support    1043.000000  4163.000000  11910.000000  4983.000000  1310.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsIB5uF6oSp4",
        "colab_type": "text"
      },
      "source": [
        "### 3. LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqjQArEiruz3",
        "colab_type": "text"
      },
      "source": [
        "#### 3.1 Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USP0t0dwryGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d80e9adf-2e7c-470b-9b1b-4c924d10739d"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(num_unique_word,100,mask_zero=True))\n",
        "model1.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
        "model1.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "model1.add(Dense(num_classes,activation='softmax'))\n",
        "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, None, 100)         1650600   \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, None, 64)          42240     \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 1,705,421\n",
            "Trainable params: 1,705,421\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7e8ibw_tpyk",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2 Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tjHB7InttAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "79fa95a1-1818-4015-800c-e5a10a082cbc"
      },
      "source": [
        "model1.fit(train_x, dummy_y_train, validation_data=(val_x, dummy_y_val),epochs=4, batch_size=128, verbose=1)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 109242 samples, validate on 23409 samples\n",
            "Epoch 1/4\n",
            "109242/109242 [==============================] - 1011s 9ms/step - loss: 1.1218 - acc: 0.5638 - val_loss: 0.9003 - val_acc: 0.6373\n",
            "Epoch 2/4\n",
            "109242/109242 [==============================] - 1006s 9ms/step - loss: 0.8411 - acc: 0.6571 - val_loss: 0.8440 - val_acc: 0.6551\n",
            "Epoch 3/4\n",
            "109242/109242 [==============================] - 1003s 9ms/step - loss: 0.7734 - acc: 0.6831 - val_loss: 0.8360 - val_acc: 0.6615\n",
            "Epoch 4/4\n",
            "109242/109242 [==============================] - 1003s 9ms/step - loss: 0.7308 - acc: 0.6995 - val_loss: 0.8350 - val_acc: 0.6618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3e2f074f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRfnRaJvuSE-",
        "colab_type": "text"
      },
      "source": [
        "#### 3.3 Model evaluation and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQCNsY5OuVlE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0208a9f3-5026-436d-e0a1-50bb7b500e50"
      },
      "source": [
        "# Calculate main metrics\n",
        "predictions = model1.predict(test_x)\n",
        "pred=[]\n",
        "for idx,val in enumerate(predictions):\n",
        "    pred.append(np.argmax(val))\n",
        "\n",
        "print('Overall model Accuracy:  %0.2f' % sklm.accuracy_score(Y_test, pred))\n",
        "print()\n",
        "\n",
        "metrics = sklm.precision_recall_fscore_support(Y_test, pred)\n",
        "cols_name = ('0','1','2','3','4')\n",
        "rows_name = ('Precision','Recall','F1-score','Support')\n",
        "print(pd.DataFrame(metrics,rows_name,cols_name))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall model Accuracy:  0.65\n",
            "\n",
            "                     0            1             2            3            4\n",
            "Precision     0.501433     0.518886      0.768761     0.552910     0.598240\n",
            "Recall        0.335570     0.590680      0.750042     0.629139     0.311450\n",
            "F1-score      0.402068     0.552460      0.759286     0.588567     0.409639\n",
            "Support    1043.000000  4163.000000  11910.000000  4983.000000  1310.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7cBrUP0-Z3X",
        "colab_type": "text"
      },
      "source": [
        "### 4. Conclusion\n",
        "We see that CNN that used Embeddings has overall same values of the main metrics"
      ]
    }
  ]
}