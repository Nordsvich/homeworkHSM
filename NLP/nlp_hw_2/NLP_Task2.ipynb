{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework â„–2: Text classification (task 2)\n",
    "*Author: Solonin Maxim*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task: \n",
    "Classify news to one of 5 categories based on text\n",
    "\n",
    "1. Choose and argue your measure of a test's accuracy.\n",
    "2. Build data processing and classification pipeline.\n",
    "3. Tune  your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data from folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way the data link of University of Dublin is broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"C:/Users/Maxim/Desktop/BBC-Dataset-News-Classification-master/dataset/data_files\"\n",
    "folders = [\"business\",\"entertainment\",\"politics\",\"sport\",\"tech\"]\n",
    "\n",
    "os.chdir(data_folder)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in folders:\n",
    "    files = os.listdir(i)\n",
    "    for text_file in files:\n",
    "        file_path = i + \"/\" +text_file\n",
    "        with open(file_path) as f:\n",
    "            data = f.readlines()\n",
    "        data = ' '.join(data)\n",
    "        x.append(data)\n",
    "        y.append(i)\n",
    "   \n",
    "data = {'news': x, 'type': y}       \n",
    "df = pd.DataFrame(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n \\n Quarter...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n \\n The doll...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n \\n The own...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n \\n British...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n \\n Shares ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news      type\n",
       "0  Ad sales boost Time Warner profit\\n \\n Quarter...  business\n",
       "1  Dollar gains on Greenspan speech\\n \\n The doll...  business\n",
       "2  Yukos unit buyer faces loan claim\\n \\n The own...  business\n",
       "3  High fuel prices hit BA's profits\\n \\n British...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n \\n Shares ...  business"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # just understand how the data looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic thing about the news texts we can get is their distribution. It is a check for sample imbalance, so that we do not face any problems in future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f4f63b7128>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "df.type.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the number of documents varies from around 400 to 500 for each class, thus we can say that the sample is pretty balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['type'].factorize()[0] # create a column with classes encoded in digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have spotted that new line symbols are presented as \"\\n\" in the docs and decided to filter them, because they do not carry a lot of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def scrub_words(text):\n",
    "    \"\"\"Basic cleaning of texts.\"\"\"\n",
    "    \n",
    "    # remove html markup\n",
    "    text=re.sub(\"\\n\",\"\",text)\n",
    "    text=text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_news = [scrub_words(w) for w in df.news]\n",
    "clean_news = pd.DataFrame(clean_news)\n",
    "df['news'] = clean_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tfidf vectorizer is equivalent to count vectorizer with tfidf transformer, but a little bit simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 34797)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(sublinear_tf=True, min_df=3, norm='l2', encoding='latin-1', ngram_range=(1, 3), stop_words='english')\n",
    "features = tf_idf.fit_transform(df.news).toarray()\n",
    "labels = df['class']\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['news'], df['class'], test_size=0.15, random_state = 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could have done all the models in one pipeline and set grid parameters for multiple classifiers, but I think it would be better to run them manually one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of doing these steps one at a time, we can use a pipeline to complete then all at once\n",
    "pipeline1 = Pipeline([('vect', tf_idf),\n",
    "                     ('chi',  SelectKBest(chi2, k=5000)),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "pipeline2 = Pipeline([('vect', tf_idf),\n",
    "                     ('chi',  SelectKBest(chi2, k=5000)),\n",
    "                     ('clf', LogisticRegression(penalty='l2',multi_class='multinomial',solver='lbfgs'))])\n",
    "\n",
    "pipeline3 = Pipeline([('vect', tf_idf),\n",
    "                     ('chi',  SelectKBest(chi2, k=5000)),\n",
    "                     ('clf', LinearSVC())])\n",
    "pipeline4 = Pipeline([('vect', tf_idf),\n",
    "                     ('chi',  SelectKBest(chi2, k=5000)),\n",
    "                     ('clf', MLPClassifier())])\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "\n",
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "#print(classification_report(ytest, model.predict(X_test)))\n",
    "#print(confusion_matrix(ytest, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        77\n",
      "           1       0.98      0.95      0.96        56\n",
      "           2       1.00      0.94      0.97        62\n",
      "           3       0.99      1.00      0.99        85\n",
      "           4       0.96      0.96      0.96        54\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       334\n",
      "   macro avg       0.97      0.97      0.97       334\n",
      "weighted avg       0.97      0.97      0.97       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_RF = pipeline1.fit(X_train,y_train)\n",
    "print(classification_report(ytest, model_RF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        77\n",
      "           1       0.98      0.95      0.96        56\n",
      "           2       1.00      0.98      0.99        62\n",
      "           3       0.99      1.00      0.99        85\n",
      "           4       0.98      0.96      0.97        54\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       334\n",
      "   macro avg       0.98      0.98      0.98       334\n",
      "weighted avg       0.98      0.98      0.98       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_LR = pipeline2.fit(X_train,y_train)\n",
    "print(classification_report(ytest, model_LR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        77\n",
      "           1       0.98      0.98      0.98        56\n",
      "           2       1.00      1.00      1.00        62\n",
      "           3       1.00      1.00      1.00        85\n",
      "           4       0.98      0.98      0.98        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       334\n",
      "   macro avg       0.99      0.99      0.99       334\n",
      "weighted avg       0.99      0.99      0.99       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_SVC = pipeline3.fit(X_train,y_train)\n",
    "print(classification_report(ytest, model_SVC.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        77\n",
      "           1       0.98      0.98      0.98        56\n",
      "           2       1.00      0.98      0.99        62\n",
      "           3       1.00      1.00      1.00        85\n",
      "           4       0.98      0.98      0.98        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       334\n",
      "   macro avg       0.99      0.99      0.99       334\n",
      "weighted avg       0.99      0.99      0.99       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_MLP = pipeline4.fit(X_train,y_train)\n",
    "print(classification_report(ytest, model_MLP.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the parameters for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = {\n",
    "    'vect__min_df': (2, 3, 5),\n",
    "    'vect__ngram_range': ((1, 2), (1, 3)),  # trigrams or bigrams\n",
    "    'chi__k': (2500,5000,\"all\"),\n",
    "    'clf__n_estimators': (100,150)\n",
    "}\n",
    "parameters2 = {\n",
    "    'vect__min_df': (2, 3, 5),\n",
    "    'vect__ngram_range': ((1, 2), (1, 3)),  # trigrams or bigrams\n",
    "    'chi__k': (2500,5000,'all'),\n",
    "    'clf__C': (0.1, 1,100),\n",
    "    'clf__solver': (['saga','lbfgs'])\n",
    "}\n",
    "parameters3 = {\n",
    "    'vect__min_df': (2, 3, 5),\n",
    "    'vect__ngram_range': ((1, 2), (1, 3)),  # trigrams or bigrams\n",
    "    'chi__k': (2500,5000,'all'),\n",
    "    'clf__multi_class':['ovr','crammer_singer'],\n",
    "    'clf__C': [0.01, 1, 100]\n",
    "}\n",
    "parameters4 = {\n",
    "    'vect__min_df': (2, 3, 5),\n",
    "    'vect__ngram_range': ((1, 2), (1, 3)),  # trigrams or bigrams\n",
    "    'chi__k': (2500,5000,'all'),\n",
    "    'clf__solver': (['sgd','lbfgs','adam'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'chi', 'clf']\n",
      "parameters:\n",
      "{'chi__k': (2500, 5000, 'all'),\n",
      " 'clf__n_estimators': (100, 150),\n",
      " 'vect__min_df': (2, 3, 5),\n",
      " 'vect__ngram_range': ((1, 2), (1, 3))}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 205.180s\n",
      "\n",
      "Best score for Random Forest: 0.961\n",
      "Best parameters set:\n",
      "\tchi__k: 5000\n",
      "\tclf__n_estimators: 150\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline1, parameters1, cv=3,\n",
    "                               n_jobs=-1, verbose=1,scoring='f1_macro')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline1.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters1)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Random Forest: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters1.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'chi', 'clf']\n",
      "parameters:\n",
      "{'chi__k': (2500, 5000, 'all'),\n",
      " 'clf__C': (0.1, 1, 100),\n",
      " 'clf__solver': ['saga', 'lbfgs'],\n",
      " 'vect__min_df': (2, 3, 5),\n",
      " 'vect__ngram_range': ((1, 2), (1, 3))}\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 38.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2335.243s\n",
      "\n",
      "Best score for Logistic Regression: 0.985\n",
      "Best parameters set:\n",
      "\tchi__k: 5000\n",
      "\tclf__C: 100\n",
      "\tclf__solver: 'lbfgs'\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Games\\Python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline2, parameters2, cv=5,\n",
    "                               n_jobs=-1, verbose=1,scoring='f1_macro')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline2.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters2)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Logistic Regression: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters2.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'chi', 'clf']\n",
      "parameters:\n",
      "{'chi__k': (2500, 5000, 'all'),\n",
      " 'clf__C': [0.01, 1, 100],\n",
      " 'clf__multi_class': ['ovr', 'crammer_singer'],\n",
      " 'vect__min_df': (2, 3, 5),\n",
      " 'vect__ngram_range': ((1, 2), (1, 3))}\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed: 21.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1285.196s\n",
      "\n",
      "Best score for Linear SVC: 0.985\n",
      "Best parameters set:\n",
      "\tchi__k: 5000\n",
      "\tclf__C: 1\n",
      "\tclf__multi_class: 'ovr'\n",
      "\tvect__min_df: 5\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline3, parameters3, cv=5,\n",
    "                               n_jobs=-1, verbose=1,scoring='f1_macro')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline3.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters3)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Linear SVC: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters3.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'chi', 'clf']\n",
      "parameters:\n",
      "{'chi__k': (2500, 5000, 'all'),\n",
      " 'clf__solver': ['sgd', 'lbfgs', 'adam'],\n",
      " 'vect__min_df': (2, 3, 5),\n",
      " 'vect__ngram_range': ((1, 2), (1, 3))}\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 54.6min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 137.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 8254.961s\n",
      "\n",
      "Best score for Multilayer Perceptron: 0.983\n",
      "Best parameters set:\n",
      "\tchi__k: 5000\n",
      "\tclf__solver: 'adam'\n",
      "\tvect__min_df: 3\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline4, parameters4, cv=5,\n",
    "                               n_jobs=-1, verbose=1,scoring='f1_macro')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline4.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters4)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score for Multilayer Perceptron: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters4.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best performing once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        77\n",
      "           1       0.98      0.98      0.98        56\n",
      "           2       1.00      0.98      0.99        62\n",
      "           3       1.00      1.00      1.00        85\n",
      "           4       1.00      0.98      0.99        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       334\n",
      "   macro avg       0.99      0.99      0.99       334\n",
      "weighted avg       0.99      0.99      0.99       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip_fin = Pipeline([('vect', TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')),\n",
    "                     ('chi',  SelectKBest(chi2, k=5000)),\n",
    "                     ('clf', LinearSVC(C = 1, multi_class = 'ovr'))])\n",
    "mod_fin = pip_fin.fit(X_train,y_train)\n",
    "print(classification_report(ytest, mod_fin.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Games\\Python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        77\n",
      "           1       0.98      0.98      0.98        56\n",
      "           2       1.00      1.00      1.00        62\n",
      "           3       1.00      1.00      1.00        85\n",
      "           4       0.98      0.98      0.98        54\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       334\n",
      "   macro avg       0.99      0.99      0.99       334\n",
      "weighted avg       0.99      0.99      0.99       334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip_fin2 = Pipeline([('vect', TfidfVectorizer(sublinear_tf=True, min_df=2, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')),\n",
    "                     ('chi',  SelectKBest(chi2, k=5000)),\n",
    "                     ('clf', LogisticRegression(C = 100, solver = 'lbfgs'))])\n",
    "mod_fin2 = pip_fin2.fit(X_train,y_train)\n",
    "print(classification_report(ytest, mod_fin2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the results before and after tuning, it can be stated that all the models perform very well with f1-scores more than 0.96. While RF model tends to use trigrams to show its best result, other models are using bigrams and have higher f1, precision and recall macro metrics. The best identified models are Logistic Regression and Linear Support Vector Classification with f1-macro 0.985 and used bigrams and 5000 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to final results, Logistic regression perfoms the best and predicts news types politics and sport 100% correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
