{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLIP. Home assignment 4.                                  Zhanna Azizova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data:\n",
    "https://www.kaggle.com/c/movie-review-sentiment-analysis-kernels-only/overview\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1. Choose and argue your measure of a test's accuracy.\n",
    "2. Build data processing and classification pipeline; Please compare word-embeddings vs classical methods \n",
    "3. Tune  your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import keras\n",
    "import multiprocessing\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import floatx\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense,Dropout,Activation, Input, Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report,confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(Y_test, y_pred, classes, title):\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50.994489\n",
       "3    21.098936\n",
       "1    17.475971\n",
       "4     5.899013\n",
       "0     4.531590\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see the classess in the sample are imbalanced (especially negative and positive)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fad4863d6d8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZohIkjr7//FdrjUoLUFVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Sentiment'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric for quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If choosing the only one, the best choices as metrics for quality evaluation for multiclass classification models is: ** f1 score**. F1-score takes into account both recall and precsision that means that it evaluates how well model distinguishes between all classes.\n",
    "\n",
    "F1 Score: It is a harmonic mean of precision and recall given by- \n",
    "F1 = 2*Precision*Recall/(Precision + Recall).\n",
    "\n",
    "Since samples of some classes are imbalanced I would choose **macro average f1-score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing and feature extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of phrases is done as follows:\n",
    "-  All words(tokens) are converted to lower case\n",
    "-  Punctuation marks are removed from the phrase.\n",
    "-  The phrase is splitted into tokens(words) from whitespace characters.\n",
    "-  Stop words are filtered with the help of stop word dictionary of NLTK library.\n",
    "-  Each token is replaced with its word stem with the help of SnowballStemmer library of NLTK.\n",
    "\n",
    "\n",
    "After preprocessing step, vocabulary is built from these tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def review_to_words(raw_review):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review)\n",
    "    words = letters_only.lower().split()\n",
    "    meaningful_words = [stemmer.stem(w) for w in words if w not in stops]\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Words'] = data['Phrase'].apply(review_to_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline building, modeling, model evaluation and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Words'], data['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample shape: (124848,)\n",
      "Test sample shape: (31212,)\n"
     ]
    }
   ],
   "source": [
    "print('Train sample shape:', X_train.shape)\n",
    "print('Test sample shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 125\n",
    "max_words = 5000\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_val = tokenizer.texts_to_sequences(X_test)\n",
    "X_val = pad_sequences(X_val, maxlen=maxlen)\n",
    "Y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "Y_val = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 100)         500000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, None, 64)          42240     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 554,821\n",
      "Trainable params: 554,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb_model = Sequential()\n",
    "\n",
    "\n",
    "emb_model.add(Embedding(max_words,100,mask_zero=True))\n",
    "emb_model.add(LSTM(64,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
    "emb_model.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "emb_model.add(Dense(5,activation='softmax'))\n",
    "emb_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112363 samples, validate on 12485 samples\n",
      "Epoch 1/5\n",
      "112363/112363 [==============================] - 917s 8ms/step - loss: 1.0497 - acc: 0.5924 - val_loss: 0.9240 - val_acc: 0.6346\n",
      "Epoch 2/5\n",
      "112363/112363 [==============================] - 919s 8ms/step - loss: 0.9022 - acc: 0.6370 - val_loss: 0.8974 - val_acc: 0.6388\n",
      "Epoch 3/5\n",
      "112363/112363 [==============================] - 915s 8ms/step - loss: 0.8609 - acc: 0.6509 - val_loss: 0.8823 - val_acc: 0.6465\n",
      "Epoch 4/5\n",
      "112363/112363 [==============================] - 925s 8ms/step - loss: 0.8322 - acc: 0.6608 - val_loss: 0.8724 - val_acc: 0.6481\n",
      "Epoch 5/5\n",
      "112363/112363 [==============================] - 918s 8ms/step - loss: 0.8077 - acc: 0.6702 - val_loss: 0.8715 - val_acc: 0.6481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa9be936da0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "emb_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "emb_model.fit(X_train, Y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31212/31212 [==============================] - 58s 2ms/step\n",
      "\n",
      "\n",
      "Test score: 0.8679424041236927\n",
      "Test accuracy: 0.6516083557606049\n"
     ]
    }
   ],
   "source": [
    "score = emb_model.evaluate(X_val, Y_val, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = emb_model.predict_classes(X_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         negative       0.56      0.33      0.41      1416\n",
      "somewhat negative       0.55      0.47      0.51      5527\n",
      "          neutral       0.73      0.80      0.76     15639\n",
      "somewhat positive       0.56      0.59      0.57      6707\n",
      "         positive       0.56      0.41      0.47      1923\n",
      "\n",
      "         accuracy                           0.65     31212\n",
      "        macro avg       0.59      0.52      0.55     31212\n",
      "     weighted avg       0.64      0.65      0.64     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['negative', 'somewhat negative', 'neutral', 'somewhat positive', 'positive']\n",
    "print(classification_report(y_test, y_pred, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras standart model with texts to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Words'], data['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bin = tokenizer.texts_to_matrix(X_train, mode='binary')\n",
    "x_test_bin = tokenizer.texts_to_matrix(X_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_bin = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Keras model \n",
    "model = Sequential([Dense(512, input_shape=(max_words,)),\n",
    "                      Activation('relu'),\n",
    "                      Dropout(0.5),\n",
    "                      Dense(num_classes),\n",
    "                      Activation('softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99878 samples, validate on 24970 samples\n",
      "Epoch 1/10\n",
      "99878/99878 [==============================] - 50s 505us/step - loss: 1.0005 - acc: 0.6046 - val_loss: 0.9075 - val_acc: 0.6340\n",
      "Epoch 2/10\n",
      "99878/99878 [==============================] - 49s 489us/step - loss: 0.8527 - acc: 0.6615 - val_loss: 0.8862 - val_acc: 0.6490\n",
      "Epoch 3/10\n",
      "99878/99878 [==============================] - 49s 490us/step - loss: 0.7931 - acc: 0.6889 - val_loss: 0.8871 - val_acc: 0.6536\n",
      "Epoch 4/10\n",
      "99878/99878 [==============================] - 49s 492us/step - loss: 0.7504 - acc: 0.7054 - val_loss: 0.8927 - val_acc: 0.6575\n",
      "Epoch 5/10\n",
      "99878/99878 [==============================] - 48s 483us/step - loss: 0.7171 - acc: 0.7199 - val_loss: 0.9059 - val_acc: 0.6587\n",
      "Epoch 6/10\n",
      "99878/99878 [==============================] - 48s 484us/step - loss: 0.6918 - acc: 0.7309 - val_loss: 0.9191 - val_acc: 0.6585\n",
      "Epoch 7/10\n",
      "99878/99878 [==============================] - 49s 489us/step - loss: 0.6708 - acc: 0.7392 - val_loss: 0.9332 - val_acc: 0.6590\n",
      "Epoch 8/10\n",
      "99878/99878 [==============================] - 48s 484us/step - loss: 0.6507 - acc: 0.7469 - val_loss: 0.9546 - val_acc: 0.6545\n",
      "Epoch 9/10\n",
      "99878/99878 [==============================] - 49s 492us/step - loss: 0.6358 - acc: 0.7531 - val_loss: 0.9710 - val_acc: 0.6558\n",
      "Epoch 10/10\n",
      "99878/99878 [==============================] - 49s 490us/step - loss: 0.6220 - acc: 0.7574 - val_loss: 0.9870 - val_acc: 0.6588\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "history = model.fit(x_train_bin, y_train_bin,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31212/31212 [==============================] - 3s 89us/step\n",
      "\n",
      "\n",
      "Test score: 0.9872797035214597\n",
      "Test accuracy: 0.6546520568973725\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test_bin, y_test_bin,batch_size=batch_size)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(x_test_bin, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         negative       0.54      0.32      0.40      1416\n",
      "somewhat negative       0.57      0.44      0.50      5527\n",
      "          neutral       0.70      0.85      0.77     15639\n",
      "somewhat positive       0.59      0.52      0.56      6707\n",
      "         positive       0.57      0.36      0.44      1923\n",
      "\n",
      "         accuracy                           0.65     31212\n",
      "        macro avg       0.59      0.50      0.53     31212\n",
      "     weighted avg       0.64      0.65      0.64     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Words'], data['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "multinomialNB = MultinomialNB()\n",
    "\n",
    "# Define pipeline\n",
    "mn_cv_nb_pipeline = Pipeline([('vectorizer', count_vectorizer),\n",
    "                             ('multinomial_nb', multinomialNB)])\n",
    "\n",
    "# Grid search parameters\n",
    "mn_cv_nb_param_grid = [\n",
    "    {   'vectorizer__min_df': [ 1, 2, 3],\n",
    "        'vectorizer__ngram_range': [ (1, 1), (1, 2), (1, 3) ],\n",
    "        'multinomial_nb__alpha': [ 0.0, 0.25, 0.5]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: {'multinomial_nb__alpha': 0.5, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best f1 score: 0.501602\n",
      "Best test f1 score: 0.605761\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "mn_cv_nb_gs = GridSearchCV(estimator=mn_cv_nb_pipeline, param_grid=mn_cv_nb_param_grid, \n",
    "                           scoring='f1_macro', cv=3, n_jobs=multiprocessing.cpu_count())\n",
    "mn_cv_nb_gs.fit(X_train, y_train)\n",
    "\n",
    "# Create an instance of the best estimator\n",
    "mn_cv_nb_best = mn_cv_nb_gs.best_estimator_\n",
    "mn_cv_nb_best.fit(X_train, y_train)\n",
    "\n",
    "print('Best model: %s' % str(mn_cv_nb_gs.best_params_))\n",
    "print('Best f1 score: %f' % mn_cv_nb_gs.best_score_)\n",
    "print('Best test f1 score: %f' % mn_cv_nb_best.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB with Tf-Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vectorizer',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop...\n",
       "                                       ('multinomial_nb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=8,\n",
       "             param_grid=[{'multinomial_nb__alpha': [0.25, 0.5],\n",
       "                          'vectorizer__min_df': [1, 2, 3],\n",
       "                          'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                          'vectorizer__norm': [None, 'l1', 'l2']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "multinomialNB = MultinomialNB()\n",
    "\n",
    "# Define pipeline\n",
    "mn_tfidfv_nb_pipeline = Pipeline([('vectorizer', tfidf_vectorizer),\n",
    "                             ('multinomial_nb', multinomialNB)])\n",
    "\n",
    "# Grid search parameters\n",
    "mn_tfidfv_nb_param_grid = [\n",
    "    {   'vectorizer__min_df': [ 1, 2, 3],\n",
    "        'vectorizer__ngram_range': [ (1, 1), (1, 2), (1, 3)],\n",
    "        'vectorizer__norm': [ None, 'l1', 'l2' ],\n",
    "        'multinomial_nb__alpha': [0.25, 0.5]}]\n",
    "\n",
    "# Perform grid search\n",
    "mn_tfidfv_nb_gs = GridSearchCV(estimator=mn_tfidfv_nb_pipeline, param_grid=mn_tfidfv_nb_param_grid, \n",
    "                           scoring='f1_macro', cv=3, n_jobs=multiprocessing.cpu_count())\n",
    "mn_tfidfv_nb_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: {'multinomial_nb__alpha': 0.25, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 3), 'vectorizer__norm': 'l2'}\n",
      "Best f1 score: 0.490842\n",
      "Best test f1 score: 0.644175\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the best estimator\n",
    "mn_tfidfv_nb_best = mn_tfidfv_nb_gs.best_estimator_\n",
    "mn_tfidfv_nb_best.fit(X_train, y_train)\n",
    "\n",
    "print('Best model: %s' % str(mn_tfidfv_nb_gs.best_params_))\n",
    "print('Best f1 score: %f' % mn_tfidfv_nb_gs.best_score_)\n",
    "print('Best test f1 score: %f' % mn_tfidfv_nb_best.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         negative       0.53      0.31      0.39      1416\n",
      "somewhat negative       0.55      0.48      0.51      5527\n",
      "          neutral       0.71      0.82      0.76     15639\n",
      "somewhat positive       0.57      0.52      0.54      6707\n",
      "         positive       0.56      0.34      0.42      1923\n",
      "\n",
      "         accuracy                           0.64     31212\n",
      "        macro avg       0.58      0.49      0.53     31212\n",
      "     weighted avg       0.63      0.64      0.63     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mn_tfidfv_nb_pred = mn_tfidfv_nb_best.predict(X_test)\n",
    "print(classification_report(y_test, mn_tfidfv_nb_pred, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Words'], data['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vectorizer',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=True,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=Non...\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=1,\n",
       "             param_grid=[{'linearSVC__C': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
       "                          'vectorizer__min_df': [1, 2, 3],\n",
       "                          'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(binary=True)\n",
    "svm = LinearSVC()\n",
    "\n",
    "# Define pipeline\n",
    "svm_pipeline = Pipeline([('vectorizer', count_vectorizer),\n",
    "                             ('linearSVC', svm)])\n",
    "\n",
    "# Grid search parameters\n",
    "svm_param_grid = [\n",
    "    {   'vectorizer__min_df': [ 1, 2, 3],\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3) ],\n",
    "        'linearSVC__C': [0.001, 0.005, 0.01, 0.05, 0.1]}]\n",
    "\n",
    "svm_gs = GridSearchCV(estimator=svm_pipeline, param_grid=svm_param_grid, \n",
    "                           scoring='f1_macro', cv=3, n_jobs=1)\n",
    "\n",
    "svm_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: {'linearSVC__C': 0.1, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 3)}\n",
      "Best f1 score: 0.516661\n",
      "Best test f1 score: 0.538239\n"
     ]
    }
   ],
   "source": [
    "svm_gs_best = svm_gs.best_estimator_\n",
    "svm_gs_best.fit(X_train, y_train)\n",
    "\n",
    "print('Best model: %s' % str(svm_gs.best_params_))\n",
    "print('Best f1 score: %f' % svm_gs.best_score_)\n",
    "print('Best test f1 score: %f' % svm_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         negative       0.51      0.36      0.42      1416\n",
      "somewhat negative       0.58      0.43      0.50      5527\n",
      "          neutral       0.70      0.87      0.78     15639\n",
      "somewhat positive       0.61      0.49      0.54      6707\n",
      "         positive       0.55      0.39      0.46      1923\n",
      "\n",
      "         accuracy                           0.66     31212\n",
      "        macro avg       0.59      0.51      0.54     31212\n",
      "     weighted avg       0.64      0.66      0.64     31212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_gs_pred = svm_gs_best.predict(X_test)\n",
    "print(classification_report(y_test, svm_gs_pred, target_names = labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best macro average F1 score (0.55) was reached by Keras model with word embeddings. However, overall the difference between models' performances is not sufficient.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
