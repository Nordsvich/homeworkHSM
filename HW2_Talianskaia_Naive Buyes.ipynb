{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hometask 2. Naive Bayes algorithm for spam classification.\n",
    "*Author: Marina Talianskaia*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import scipy\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ..."
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('C:\\\\For Python\\SMSSpamCollection.csv', sep='\\t',names=['label','message'])\n",
    "data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of colums 2 , number of lines 5572\n",
      "Number of observetions in each class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Number of colums', data.shape[1], ', number of lines', data.shape[0])\n",
    "print ('Number of observetions in each class:')\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Quality metric comment:\n",
    "As the classes are of different size, we can observe a sample imbalance problem, though, accuracy will not be a good metric to evaluate the quality of model as it is biased to the larger class. So, I would choose F1-score metric as the one including both Presion and Recall opitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-labling 'spam' and 'ham' as 0(ham) and 1(spam)\n",
    "data['label'] = data.label.map({'spam':1,'ham':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spitting on test and training samples:\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['message'],data['label'],random_state=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data processing via Vectorizer\n",
    "vector = CountVectorizer(lowercase=True, stop_words='english')\n",
    "X_train_trans = vector.fit_transform(X_train)\n",
    "X_test_trans = vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 'Manual' Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes theorem looks like this:\n",
    "$$P(A | B) = P(B | A) * P(A) / P(B) $$\n",
    "\n",
    "where A = Spam and B = Ham\n",
    "\n",
    "So, we need to find the following variables:\n",
    "- Generall probability of any message being a Spam: P(spam)\n",
    "\n",
    "$$P(spam) = \\frac{Quanity\\ of\\ spam\\ lebeled\\ massages}{total\\ quantity\\ of\\ massages}$$\n",
    "\n",
    "- General probability of any message being a Ham: P(ham)\n",
    "$$P(ham) = \\frac{Quanity\\ of\\ ham\\ lebeled\\ massages}{total\\ quantity\\ of\\ massages}$$\n",
    "\n",
    "- Probability of a word appearing in spam messages: P(word|spam)\n",
    "- Probability of a word appearing in ham messages: P(word|ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13208901651112706"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability of a message being a Spam\n",
    "p_spam = sum(y_train) / len(y_train)\n",
    "p_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867910983488873"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability of a message being a Ham\n",
    "p_ham = 1 - sum(y_train) / len(y_train)\n",
    "p_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(word1 | ham) = \\frac{qty\\ of\\ word1\\ belonging\\ to\\ category\\ ham}{total\\ qty\\ of\\ words\\ belonging\\ to\\ category\\ ham} $$\n",
    "\n",
    "\n",
    "$$P(word1 | spam) = \\frac{qty\\ of\\ word1\\ belonging\\ to\\ category\\ spam}{total\\ qty\\ of\\ words\\ belonging\\ to\\ category\\ spam} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time, it is possible that some words of full dataset are not represented in our testing dataset, but appear in test sample, thus, it leads the situation when the equatation is equal to null. Thus, some technical transformations to avoid it are necessary. Let's apply the following formulas:\n",
    "\n",
    "$$P(word1|ham)== \\frac{qty\\ of\\ word1\\ belonging\\ to\\ category\\ ham\\ + 1}{total\\ qty\\ of\\ words\\ in\\ ham\\ masseges}$$\n",
    "\n",
    "$$P(word1|spam)== \\frac{qty\\ of\\ word1\\ belonging\\ to\\ category\\ spam\\ + 1}{total\\ qty\\ of\\ words\\ in\\ spam\\ masseges}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<552x7252 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8391 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Array containing all spam-labeled massages:\n",
    "spam_array = np.where(y_train == 1)[0]\n",
    "#Sparce matrix with all spam messages\n",
    "spam = X_train_trans.tocsr()[spam_array]\n",
    "spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3627x7252 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 24375 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Array containing all ham-labeled massages:\n",
    "ham_array = np.where(y_train == 0)[0]\n",
    "#Sparce matrix with all spam messages\n",
    "ham = X_train_trans.tocsr()[ham_array]\n",
    "ham\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define how many times each word appears in Ham-labled messages (in the array format)\n",
    "ham_freq = ham.toarray().sum(axis=0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define how many times each word appears in Ham-labled messages (in the array format)\n",
    "spam_freq = spam.toarray().sum(axis=0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.04757261e-05, 3.04757261e-05, 6.09514522e-05, ...,\n",
       "       6.09514522e-05, 3.04757261e-05, 6.09514522e-05])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the probabilities of each word being in a spam message:\n",
    "ham_sum = sum(ham_freq)\n",
    "ham_prob = ham_freq/ham_sum\n",
    "ham_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.98038972e-04, 1.55637179e-03, 6.22548714e-05, ...,\n",
       "       6.22548714e-05, 1.24509743e-04, 6.22548714e-05])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the probabilities of each word being in a spam message:\n",
    "spam_sum = sum(spam_freq)\n",
    "spam_prob = spam_freq/spam_sum\n",
    "spam_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, let's apply log on both sides of equatation:\n",
    "$$log(P(ham | bodyText)) = log(P(ham)) + \\sum\\limits_{i=1}^n log(P(word_i | ham))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if (log(P(ham | bodyText)) > log(P(spam | bodyText))) {return ‘ham’;} else {return ‘spam’; }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(df):\n",
    "    prob_ham = np.log(p_ham)\n",
    "    prob_spam = np.log(p_spam)\n",
    "    df = scipy.sparse.find(df)\n",
    "    for i in range(len(df[1])):\n",
    "        prob_ham = prob_ham + np.log(ham_prob[df[1][i]]) * df[2][i]\n",
    "        prob_spam = prob_spam + np.log(spam_prob[df[1][i]]) * df[2][i]\n",
    "\n",
    "    if prob_ham >= prob_spam:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "ans = []\n",
    "for i in X_test_trans:\n",
    "    ans.append(spam_or_ham(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      1198\n",
      "          1       0.94      0.90      0.92       195\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 'Automatic' Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = MultinomialNB()\n",
    "NB.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      1198\n",
      "          1       0.94      0.90      0.92       195\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, NB.predict(X_test_trans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 scores:  [0.92173913 0.92982456 0.93693694 0.93965517 0.89867841]\n",
      "Average F1 score:  0.9253668430571876\n"
     ]
    }
   ],
   "source": [
    "valid_results = cross_validate(estimator=NB, X=X_train_trans, y=y_train, cv=5, scoring='f1')\n",
    "print('F1 scores: ', valid_results['test_score'])\n",
    "print('Average F1 score: ', np.mean(valid_results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Commens and results\n",
    "\n",
    "We see that the 'manual' model performs the same as the sklearn NB-classificator and its overall pridictive power around 0.98 according to F1-score metric. At the same time, we can observe that the minor class represents lower performance, so, it's a sample imbalanced problem and the resuts are spoiled in favour of majority class. In practical sense, it depends on what we find more important: miss no spam or let good messages be filtered as spam.\n",
    "\n",
    "\n",
    "*Note: I finally failed to code the Step 2 (after counting frequency of each word in text massive), despite catching the mathemathic sense of the issue, thus, some ideas were taken from the work my colleagues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
