{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## DATA PREPORATION"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_raw=pd.read_csv('SMSSpamCollection.csv',header=-1, delimiter=\"\\t\", quoting=3,names=['labels','data'])",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_raw.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  labels                                               data\n0    ham  Go until jurong point, crazy.. Available only ...\n1    ham                      Ok lar... Joking wif u oni...\n2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3    ham  U dun say so early hor... U c already then say...\n4    ham  Nah I don't think he goes to usf, he lives aro..."
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# encode labels\ndata_raw['labels'] = data_raw['labels'].map({'spam':1,'ham':0})",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Transform text to vec\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(data_raw.data)\ndata=pd.DataFrame(data=X.toarray(),columns=vectorizer.get_feature_names())\n",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data['labels']=data_raw['labels']",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train, X_test = train_test_split(data, test_size=0.33, random_state=42)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## CHECK SKYLEARN BAYES FIRST"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import MultinomialNB\nnaive_bayes = MultinomialNB()\nnaive_bayes.fit(X_train.iloc[:,:-1], X_train.iloc[:,-1])",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_true = X_test.iloc[:,-1].values\ny_pred = naive_bayes.predict_proba(X_test.iloc[:,:-1]).argmax(axis=1)\nprint(classification_report(y_true, y_pred))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.99      0.99      0.99      1585\n          1       0.93      0.96      0.94       255\n\navg / total       0.98      0.98      0.98      1840\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## CREATE OWN BAYES"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class my_bayes_v1(object):\n    def __init__(self):\n        print ('NOTE:INPUT DATA HAS TO BE PANDAS DATA FRAME TYPE!!!')\n        print ('Labeled data has to be a last column and call: labels')\n        print ('Alpha=0.001')\n        self.P_w_class = 0\n        self.P_class = 0\n        self.alfa=0.001\n    def fit(self,X_train):\n        #split classes\n        Clas=[X_train[X_train['labels']==0].iloc[:,:-1],\n              X_train[X_train['labels']==1].iloc[:,:-1]]\n        X_train=X_train.iloc[:,:-1]\n        #P(clas)\n        P_class=[Clas[0].shape[0]/X_train.shape[0],\n                 Clas[1].shape[0]/X_train.shape[0]]\n        #P_w_class\n        P_w_class=[self.alfa+Clas[0].sum()/(self.alfa*X_train.sum().sum()+Clas[0].sum().sum()),\n                   self.alfa+Clas[1].sum()/(self.alfa*X_train.sum().sum()+Clas[1].sum().sum())]\n        self.P_w_class=P_w_class\n        self.P_class=P_class\n    def proba(self,X):\n        prob=[self.P_w_class[0][X>0].product()*self.P_class[0],\n              self.P_w_class[1][X>0].product()*self.P_class[1]]\n        #requlize prob\n        prob=[prob[0]/(prob[1]+prob[0]),prob[1]/(prob[1]+prob[0])]\n        return prob\n    def predict_proba(self,X):\n        n=[]\n        if np.array(X.shape).shape[0]==1:\n            X=pd.DataFrame(data=X.values.reshape(1,X.shape[0]),columns=X.index)\n        for i in range(0,X.shape[0]):\n            n.append(self.proba(X.iloc[i,:]))\n        return np.array(n)\n    def predict(self,X):\n        prob=self.predict_proba(X)\n        a=np.array([(prob[:,0]==prob.max(axis=1))+0,\n           (prob[:,1]==prob.max(axis=1))+0])\n        return a.T\n",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "a=my_bayes_v1()",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "NOTE:INPUT DATA HAS TO BE PANDAS DATA FRAME TYPE!!!\nLabeled data has to be a last column and call: labels\nAlpha=0.001\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "a.alfa=0.00001",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "a.fit(X_train)",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_true = X_test.iloc[:,-1].values\ny_pred = a.predict(X_test.iloc[:,:-1]).argmax(axis=1)\nres=f1_score(y_true, y_pred, average='micro')\nprint(classification_report(y_true, y_pred))",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.99      0.99      0.99      1585\n          1       0.96      0.93      0.95       255\n\navg / total       0.99      0.99      0.99      1840\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Best F1 score ~98, custom bayes resuls are near to skylearn bayes results "
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}