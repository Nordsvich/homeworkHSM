{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLIP. Home assignment 2.                                  Zhanna Azizova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import nltk\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation and analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data \n",
    "data = pd.read_csv('SMSSpamCollection', sep='\\t', names=[\"label\", \"sms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all sms messages: 5572\n",
      "Number of unique sms messages: 5169\n"
     ]
    }
   ],
   "source": [
    "# check duplicates in our dataset\n",
    "print(\"Number of all sms messages:\", len(data))\n",
    "print(\"Number of unique sms messages:\",len(data['sms'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "data = data.drop_duplicates('sms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4516\n",
       "spam     653\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('label').size() # The classes in the sample are clearly imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metric for quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best choices as metrics for quality evaluation for the model are: **recall, precsicion and f1 score** for both classes.\n",
    "\n",
    "Due to imbalance in the sample (in favour of ham messages) there is high chance to receive good metrics for class 0 (ham messages) prediction while metrics for class 1 (spam) detection might be not good enough. Therefore it is important to get classifier which perfectly separates classes 0 and 1. For this purpose accuracy is not representative metric and in the best scenario we should have equally high recall for each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data processing and feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode labels to binary variable replace \n",
    "data['label'] = data['label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a fixed split into training and test samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['sms'], data['label'], test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.876904\n",
       "1    0.123096\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.860735\n",
       "1    0.139265\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True)  # we have checked proportionality in sizes of the classes size after splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a sklearns count vectorizer method the messages in the dataset will be converted to a matrix, with each message being a row and each word(token) being the column, and the corresponding (row,column) values being the frequency of occurrence of each word or token in that sms message.\n",
    "\n",
    "Algorithm for sklearns count vectorizer method:\n",
    "* It tokenizes the string(separates the string into individual words) and gives an integer ID to each token.\n",
    "* It counts the occurrence of each of those tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can imagine this as a 2-Dimensional matrix. Where the 1-dimension is the entire vocabulary (1 row per word) and the other dimension are the actual messages, in this case a column per text message. We will also concider removal of stop words from our messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer(analyzer = 'word', stop_words='english', binary = False, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Sklearn NB model\n",
    "X_train_counts = count_vector.fit_transform(X_train)\n",
    "X_test_counts = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes for self-made NB model\n",
    "X_tr_df = pd.DataFrame(X_train_counts.toarray(), columns = count_vector.get_feature_names())\n",
    "X_ts_df = pd.DataFrame(X_test_counts.toarray(), columns = count_vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4135, 31026), (1034, 31026))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_df.shape, X_ts_df.shape # there are 31026 unique words (features) in our training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Naive bayes model training (by hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ P(ham | smsText) $ = Probability that sms is ham given that it contains content - smsText \n",
    "\n",
    "* $ P(spam | smsText) $  = Probability that sms is spam given that it contains content - smsText \n",
    "\n",
    "$$ P(ham | smsText) = \\frac{P(ham) * P(smsText | ham)}{ P(smsText)} $$\n",
    "\n",
    "$$ P(spam | smsText) = \\frac{P(spam) * P(smsText | spam)}{P(smsText)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since P(smsText) is constant and common in both expressions, we can avoid it. \n",
    "\n",
    "$$ P(ham) = \\frac{numberofmessagesbelongingtocategoryham}{totalNofmessages} $$\n",
    "\n",
    "$$ P(spam) = \\frac{(numberofmessagesbelongingtocategoryspam)}{totalNofmessages} $$\n",
    "\n",
    "To calculate the above two probabilities, we’ll use training Set table.\n",
    "\n",
    "$$ P(smsText | spam) = P(word1 | spam) * P(word2 | spam) * … $$\n",
    "\n",
    "$$ P(smsText | ham) = P(word1 | ham) * P(word2 | ham) * … $$\n",
    "\n",
    "To calculate the above two probabilities, we’ll use wordFrequency table. Here word1, word2, word3 up to word-n are total words in smstext.\n",
    "\n",
    "$$ P(word1 | spam) = \\frac{count of word1 belonging to category spam}{total count of words belonging to category spam}.$$\n",
    "\n",
    "$$ P(word1 | ham) = \\frac{count of word1 belonging to category ham}{total count of words belonging to category ham}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To solve this problem when the classifier detects a new word that is not present in training data sets, we will take log on both sides.\n",
    "\n",
    "$$ log(P(ham | smsText)) = log(P(ham)) + log(P(smsText | ham)) = log(P(ham)) + log(P(word1 | ham)) + log(P(word2 | ham)) … $$\n",
    "\n",
    "To solve the problem when a classifier encounters a new word that is not present in our training data sets, we’ll use Laplace smoothing. Now we’ll have-\n",
    "\n",
    "$$ P(word1 | ham) = (count of word1 belonging to category ham + 1) / (total count of words belonging to ham + N of distinct words in training data sets) $$\n",
    "\n",
    "$$ P(word1 | spam) = (count of word1 belonging to category spam + 1) / (total count of words belonging to spam + N of distinct words in training data sets) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_NB(X_train, y_train):\n",
    "    \n",
    "    #count_vector = CountVectorizer(analyzer = 'word', stop_words='english', binary = False, ngram_range=(1, 2))\n",
    "    #X_train_counts = count_vector.fit_transform(X_train)\n",
    "    #X_train = pd.DataFrame(X_train_counts.toarray(), columns = count_vector.get_feature_names())\n",
    "    \n",
    "    P_ham = len(y_train[y_train == 0]) / len(y_train) # Probability that chosen message belongs to ham\n",
    "    P_spam = len(y_train[y_train == 1]) / len(y_train) # Probability that chosen message belongs to spam\n",
    "    \n",
    "    classes_probs = [P_ham, P_spam]\n",
    "    \n",
    "    ham_data = X_train[X_train.index.isin(y_train[y_train == 0].index)]\n",
    "    spam_data = X_train[X_train.index.isin(y_train[y_train == 1].index)]\n",
    "    \n",
    "    unique_words_in_train_data = X_train.shape[1]\n",
    "\n",
    "    n_words_in_ham_data = ham_data.sum().sum()\n",
    "    n_words_in_spam_data = spam_data.sum().sum()\n",
    "    \n",
    "    n_words = [n_words_in_ham_data + unique_words_in_train_data, n_words_in_spam_data + unique_words_in_train_data]\n",
    "    #n_words = [n_words_in_ham_data, n_words_in_spam_data]\n",
    "\n",
    "    words_frequences_for_ham = ham_data.sum(axis=0) + 1 #  add 1 to frequencies for Laplas smoothing purpose\n",
    "    words_frequences_for_spam = spam_data.sum(axis=0) + 1\n",
    "    \n",
    "    probs_for_ham = words_frequences_for_ham/n_words_in_ham_data \n",
    "    probs_for_spam = words_frequences_for_spam/n_words_in_spam_data \n",
    "\n",
    "    return classes_probs, probs_for_ham, probs_for_spam  # return P(C) and P(Wi|C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_predict(model, X_test):\n",
    "        \n",
    "    pred = []\n",
    "    \n",
    "    classes_probs, probs_for_ham, probs_for_spam = model\n",
    "    \n",
    "    for vec in X_test:\n",
    "        prob_for_ham = np.log(classes_probs[0])\n",
    "        prob_for_spam = np.log(classes_probs[1])\n",
    "        \n",
    "        non_zero_words = scipy.sparse.find(vec)\n",
    "        \n",
    "        for i in range(len(non_zero_words[1])): # iterations over all words\n",
    "            prob_for_ham += np.log(probs_for_ham[non_zero_words[1][i]]) * non_zero_words[2][i]\n",
    "            prob_for_spam += np.log(probs_for_spam[non_zero_words[1][i]]) * non_zero_words[2][i]\n",
    "        \n",
    "        if prob_for_spam > prob_for_ham:\n",
    "            pred.append(1)\n",
    "        else: \n",
    "            pred.append(0)\n",
    "\n",
    "    \n",
    "    result = pd.Series(pred, name = 'predicted')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "NB_classifier  = train_NB(X_tr_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "\n",
    "y_pred = NB_predict(NB_classifier, X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.31      0.47       890\n",
      "           1       0.18      0.94      0.30       144\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      1034\n",
      "   macro avg       0.57      0.63      0.39      1034\n",
      "weighted avg       0.86      0.40      0.45      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x16b520240>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEmCAYAAAAtGCajAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlpRDyMyS+v9ROk8Ah/CCFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16b5224a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['ham', 'spam']\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix for NB coded by hand')\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Classifier poorly separates spam from ham. It often classifies ham as spam by mistake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing results with sklearn NB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, we will be using the multinomial Naive Bayes implementation. This particular classifier is suitable for classification with discrete features (such as in our case, word counts for text classification). It takes in integer word counts as its input. On the other hand Gaussian Naive Bayes is better suited for continuous data as it assumes that the input data has a Gaussian(normal) distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skleran_NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNB implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice). The distribution is parametrized by vectors \n",
    "$\\theta_y = (\\theta_{y1},\\ldots,\\theta_{yn})$\n",
    " for each class \n",
    "y\n",
    ", where \n",
    "n\n",
    " is the number of features (in text classification, the size of the vocabulary) and $\\theta_{yi}$\n",
    " is the probability $P(x_i \\mid y)$\n",
    "of feature *i*\n",
    " appearing in a sample belonging to class *y*.\n",
    "The parameters $\\theta_y$ is estimated by a smoothed version of maximum likelihood, i.e. relative frequency counting:\n",
    " \n",
    "$$ \\hat{\\theta}_{yi} = \\frac{ N_{yi} + \\alpha}{N_y + \\alpha n} $$\n",
    "where \n",
    "$N_{yi} = \\sum_{x \\in T} x_i$\n",
    " is the number of times feature *i* appears in a sample of class *y* in the training set *T*, and $N_{y} = \\sum_{i=1}^{n} N_{yi}$\n",
    " is the total count of all features for class *y*.\n",
    "The smoothing priors \n",
    "α\n",
    "≥\n",
    "0\n",
    " accounts for features not present in the learning samples and prevents zero probabilities in further computations. Setting \n",
    "α\n",
    "=\n",
    "1\n",
    " is called Laplace smoothing, while \n",
    "α\n",
    "<\n",
    "1\n",
    " is called Lidstone smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the sklearn Naive Bayes model\n",
    "skleran_NB.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sk_learn_pred = skleran_NB.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99       890\n",
      "        spam       0.99      0.94      0.96       144\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1034\n",
      "   macro avg       0.99      0.97      0.98      1034\n",
      "weighted avg       0.99      0.99      0.99      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, sk_learn_pred, target_names = ['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC scores [1.   0.96 0.97 0.97 0.99]\n",
      "AUC 95 prc confidence interval: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# perform 5-fold CV\n",
    "scores = cross_validate(skleran_NB, X_test_counts, y_test, cv=5, scoring=('roc_auc'))\n",
    "print(\"AUC scores\", scores['test_score'].round(4))\n",
    "    # with 95% confidence interval\n",
    "print(\"AUC 95 prc confidence interval: %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,sk_learn_pred)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12044ea20>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEmCAYAAABSyTRSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWfw/ZBmhPxvuAswAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1206b55f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['ham', 'spam']\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix for sklearn NB')\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** As we can see, in this case the best algorithm for classification is sklearn Multinominal Naive Bayes **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
